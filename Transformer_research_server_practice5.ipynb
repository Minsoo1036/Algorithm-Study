{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f59fc18b",
   "metadata": {},
   "source": [
    "# 트랜스포머 리서치서버 연계 - 브렌트유 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e995ef1",
   "metadata": {},
   "source": [
    "## 주의) Output_len, 데이터프레임, dbcode, search_cols 바꿀것!! (총 네가지 스텝)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84b3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run kpds_db_new.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06df45b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LSTM_raw2', 'weather', 'KPDS_fore_old', 'nprophet_kms', 'curr_utd', 'LSTM_raw_all', 'transformer_kms', 'prelim_dat', 'foo_score', 'all_possible_ols', 'all_possible', 'garch_kms', 'pm_ens', 'curr_clean', 'foo_all', 'curr_run', 'dbcode_list', 'prophet_kms', '1st_ens_kms', 'arima_ens', 'nprophet_step_kms', 'web_scraped_news2', 'all_ols', 'meta_score', 'lstm_ens', 'zs_pm', 'web_scraped_news', 'arima_ens_alt', 'news_update_info', 'wave_raw', 'coll_list', 'LSTM_raw3', 'CFTC_COT', 'arima_mth', 'dtw_pm', 'pca_pm', 'all_possible_corr', 'PM_en', 'LSTM_clean', 'weather_pm', 'aif_official', 'lstm_kms', 'LSTM_raw_fin', 'spotnews', 'dashboard', 'LSTM_raw']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pymongo\n",
    "\n",
    "# MongoDB 연결\n",
    "userid = 'comm'\n",
    "password = 'koreapds'\n",
    "client = pymongo.MongoClient(f'mongodb://{userid}:{password}@192.168.0.124:27017/commodity')\n",
    "\n",
    "# MongoDB collection\n",
    "db = client['commodity']\n",
    "\n",
    "# Collection list 확인\n",
    "print(db.list_collection_names())\n",
    "\n",
    "raw_coll = db['transformer_kms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e301c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbcode = \"02-01-01-00-02-00-1301-NO\"\n",
    "#while raw_coll.find_one({'dbcode':dbcode}) != None:\n",
    "#    raw_coll.delete_one({'dbcode':dbcode})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba22500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sam = raw_coll.find_one({'dbcode':dbcode})\n",
    "#list(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0addec",
   "metadata": {},
   "source": [
    "## 트랜스포머 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "309f37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn import Transformer\n",
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pymongo\n",
    "\n",
    "# MongoDB 연결\n",
    "userid = 'comm'\n",
    "password = 'koreapds'\n",
    "client = pymongo.MongoClient(f'mongodb://{userid}:{password}@192.168.0.124:27017/commodity')\n",
    "\n",
    "# MongoDB collection\n",
    "db = client['commodity']\n",
    "\n",
    "# Collection list 확인\n",
    "#print(db.list_collection_names())\n",
    "\n",
    "raw_coll = db['transformer_kms']\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class windowDataset(Dataset):\n",
    "    '''\n",
    "    데이터 생성을 위한 class : enc_len, pred_len, label_len, output_dim 등 지정 가능.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, data, enc_len=80, pred_len=1, label_len=1, output_dim=1, stride=1):\n",
    "        #input_window ---> enc_len\n",
    "        #y ---> data\n",
    "        #output_windw ---> dec_len = label_len + pred_len\n",
    "\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = pred_len\n",
    "        self.dec_len = label_len+pred_len #length of decoder input\n",
    "        self.enc_len = enc_len\n",
    "\n",
    "        #총 데이터의 개수\n",
    "        L = data.shape[0]\n",
    "        #stride씩 움직일 때 생기는 총 train data의 개수\n",
    "        num_samples = (L - self.enc_len - self.pred_len) // stride + 1\n",
    "\n",
    "        X = np.zeros([self.enc_len, num_samples, output_dim])\n",
    "        Y = np.zeros([self.dec_len, num_samples, output_dim]) \n",
    "\n",
    "        for i in np.arange(num_samples):\n",
    "            #encoder input part\n",
    "            start_x = stride*i\n",
    "            end_x = start_x + self.enc_len\n",
    "            X[:,i,:] = data[start_x:end_x,:]\n",
    "\n",
    "            #decoder input part\n",
    "            start_y = end_x - self.label_len\n",
    "            end_y = end_x + self.pred_len\n",
    "            Y[:,i,:] = data[start_y:end_y,:]\n",
    "\n",
    "\n",
    "        X = X.reshape(X.shape[0], X.shape[1], output_dim).transpose((1,0,2)) # [num_samples, enc_len, output_dim]\n",
    "        Y = Y.reshape(Y.shape[0], Y.shape[1], output_dim).transpose((1,0,2)) # [num_samples, dec_len, output_dim]\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.len = len(X) #number of train data\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i, :, :], self.y[i,self.label_len:, :]  #enc_input, dec_input, pred_output\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "class TFModel(nn.Module):\n",
    "    def __init__(self,d_model, nhead, nhid, nlayers, output_dim = 1, dropout=0.5): #outpud_dim (multivariate dimension)\n",
    "        \"\"\"\n",
    "        nhead = number of head in multi head attention\n",
    "        output_dim: 훈련시키고자 하는 데이터가 만약 multidimension이라면 해당 dimension의 개수 \n",
    "        \"\"\"\n",
    "        super(TFModel, self).__init__()\n",
    "        self.transformer = Transformer(d_model=d_model, nhead=nhead, dim_feedforward=nhid, num_encoder_layers=nlayers, num_decoder_layers=nlayers,dropout=dropout)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        self.pos_encoder_d = PositionalEncoding(d_model, dropout)\n",
    "        self.linear = nn.Linear(d_model, output_dim) #for multivariate\n",
    "        # Inputs의 encoder\n",
    "        self.encoder = nn.Linear(output_dim, d_model)\n",
    "        # Outputs의 encoder\n",
    "        self.encoder_d = nn.Linear(output_dim, d_model)\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, tgt, srcmask, tgtmask):\n",
    "        # 어차피 처음 encoder 처리를 해줄 때 dimension자체가 d_model을 가지도록 조정되기에 \n",
    "        # mask나 positional_encoding을 따로 multi dimension setting에 맞도록 조정해줄 필요가 없음\n",
    "        src = self.encoder(src)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        tgt = self.encoder_d(tgt)\n",
    "        tgt = self.pos_encoder_d(tgt)\n",
    "        output = self.transformer(src.transpose(0,1), tgt.transpose(0,1), srcmask, tgtmask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def gen_attention_mask(x):\n",
    "    mask = torch.eq(x, 0)\n",
    "    return mask\n",
    "\n",
    "def TF_train(model, train_loader, optimizer, log_interval, scheduler = None, label_len=0, epoch=1, verbose = True):\n",
    "    model.train()\n",
    "    for batch_idx, (inputs, dec_inputs, outputs) in enumerate(train_loader):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        dec_inputs = dec_inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        dec_inputs = dec_inputs.permute(1,0,2)\n",
    "        dec_inputs[label_len:] = 0\n",
    "        dec_inputs = dec_inputs.permute(1,0,2)\n",
    "\n",
    "        src_mask = model.generate_square_subsequent_mask(inputs.shape[1]).to(device)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(dec_inputs.shape[1]).to(device)\n",
    "\n",
    "        result = model(inputs.float().to(device), dec_inputs.float().to(device), src_mask, tgt_mask)\n",
    "        loss = criterion(result[label_len:].permute(1,0,2), outputs.float().to(device))\n",
    "\n",
    "        loss.backward()\n",
    "        # gradient exploding을 막기 위해 아래 방법을 사용 (https://sanghyu.tistory.com/87 참조) -> 다만 아래 방법을 사용하면 \n",
    "        # Optimal한 결론에 도달하지 못할 가능성도 존재함 \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()     \n",
    "\n",
    "        # scheduler가 존재하는 경우에 값들을 training 하면서 조정 \n",
    "        if scheduler != None:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            if verbose:\n",
    "                print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                    epoch, batch_idx * len(inputs), \n",
    "                    len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                    loss.item()))\n",
    "\n",
    "''' 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
    "def TF_evaluate(model, valid_loader, label_len=0):            \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_pred_df = np.array([0]*pred_len).reshape(1,-1)\n",
    "    valid_iter = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, dec_inputs, outputs in valid_loader:\n",
    "\n",
    "            valid_iter+=1\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            dec_inputs = dec_inputs.to(device)\n",
    "            outputs = outputs.to(device)\n",
    "\n",
    "            dec_inputs = dec_inputs.permute(1,0,2)\n",
    "            dec_inputs[label_len:] = 0\n",
    "            dec_inputs = dec_inputs.permute(1,0,2)\n",
    "\n",
    "            src_mask = model.generate_square_subsequent_mask(inputs.shape[1]).to(device)\n",
    "            tgt_mask = model.generate_square_subsequent_mask(dec_inputs.shape[1]).to(device)\n",
    "\n",
    "            result = model(inputs.float().to(device), dec_inputs.float().to(device), src_mask, tgt_mask)\n",
    "            if valid_iter <= len(valid_loader.dataset)-pred_len: #output의 실제값이 pred_len개 모두 존재하는 구간\n",
    "                valid_loss += len(inputs)*criterion(result[label_len:].permute(1,0,2), outputs.float().to(device))/(len(valid_loader.dataset)-pred_len)  \n",
    "            valid_pred_df = np.concatenate([valid_pred_df,result[label_len:].permute(1,0,2)[:,:,0].cpu()*(max_y-min_y)+min_y])\n",
    "\n",
    "        #valid_1m_mape 계산\n",
    "        valid_pred_df = valid_pred_df[1:,:]\n",
    "        valid_y_temp = valid_y.reset_index()\n",
    "        valid_y_temp = valid_y_temp.drop(\"index\",axis=1)\n",
    "        valid_y_temp['pred'] = pd.Series(np.array([-100]*52))\n",
    "        valid_y_temp['ind']=valid_y_temp['Date'].map(lambda x: str(x.year)) + valid_y_temp['Date'].map(lambda x: '0'+str(x.month) if x.month<10 else str(x.month))\n",
    "\n",
    "        pred = np.array([])\n",
    "        start = 0\n",
    "        for i in range(len(list(valid_y_temp.groupby('ind').size()))):\n",
    "            month_len = list(valid_y_temp.groupby('ind').size())[i]\n",
    "            if i==0:\n",
    "                pred = np.concatenate([pred,np.array(train_y['data'])[-1]*np.exp(np.cumsum(valid_pred_df[start,:][:month_len]))])\n",
    "                start+=month_len\n",
    "            else:\n",
    "                np.array(valid_y['data'])[start-1]\n",
    "                pred = np.concatenate([pred,np.array(valid_y['data'])[start-1]*np.exp(np.cumsum(valid_pred_df[start,:][:month_len]))])\n",
    "                start+=month_len\n",
    "\n",
    "        valid_y_temp['pred'] = pd.Series(pred)\n",
    "        valid_y_temp = valid_y_temp[['data','pred','ind']]\n",
    "        valid_y_month = pd.DataFrame(valid_y_temp.groupby(\"ind\").mean())\n",
    "\n",
    "        valid_1m_mape = abs(np.array(100*(valid_y_month['data']-valid_y_month['pred'])/valid_y_month['data'])).mean() #1 month valid mape\n",
    "\n",
    "        return valid_loss, valid_1m_mape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5b070",
   "metadata": {},
   "source": [
    "## 트랜스포머 파라미터 설정 (추후 optuna 통해서 optimize됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb32f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 모델 구조와 관련된 파라미터 ####\n",
    "\n",
    "enc_len = 52*2 #intput_len\n",
    "label_len = 4\n",
    "pred_len = 17  #output_len (1st step)\n",
    "stride = 1\n",
    "d_model = 256 #256\n",
    "nhead = 8\n",
    "nhid = 256\n",
    "nlayers = 4\n",
    "dropout = 0.1\n",
    "\n",
    "\n",
    "#### 모델 학습과 관련된 파라미터 ####\n",
    "\n",
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05419e2e",
   "metadata": {},
   "source": [
    "## 데이터 로딩 및 interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "121eab49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>data</th>\n",
       "      <th>d2</th>\n",
       "      <th>d6</th>\n",
       "      <th>d9_lag1</th>\n",
       "      <th>d16</th>\n",
       "      <th>d23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>114.834</td>\n",
       "      <td>978272.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.667</td>\n",
       "      <td>4498.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>107.548</td>\n",
       "      <td>976951.0</td>\n",
       "      <td>19960.0</td>\n",
       "      <td>33720.0</td>\n",
       "      <td>109.474</td>\n",
       "      <td>4577.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>103.720</td>\n",
       "      <td>982434.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.337</td>\n",
       "      <td>4515.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>105.900</td>\n",
       "      <td>969713.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.216</td>\n",
       "      <td>4412.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>108.338</td>\n",
       "      <td>967494.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.743</td>\n",
       "      <td>4395.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>105.224</td>\n",
       "      <td>965712.0</td>\n",
       "      <td>20040.0</td>\n",
       "      <td>34020.0</td>\n",
       "      <td>113.923</td>\n",
       "      <td>4214.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>109.196</td>\n",
       "      <td>967208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.698</td>\n",
       "      <td>4181.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>106.982</td>\n",
       "      <td>958804.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.524</td>\n",
       "      <td>3976.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>111.974</td>\n",
       "      <td>951814.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.646</td>\n",
       "      <td>3964.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>114.148</td>\n",
       "      <td>941325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.220</td>\n",
       "      <td>4022.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>117.364</td>\n",
       "      <td>936081.0</td>\n",
       "      <td>20350.0</td>\n",
       "      <td>33530.0</td>\n",
       "      <td>113.017</td>\n",
       "      <td>4129.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>121.748</td>\n",
       "      <td>930326.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.753</td>\n",
       "      <td>4063.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>118.976</td>\n",
       "      <td>923146.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.129</td>\n",
       "      <td>3723.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>111.934</td>\n",
       "      <td>913434.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.516</td>\n",
       "      <td>3808.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>111.578</td>\n",
       "      <td>915828.0</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>33740.0</td>\n",
       "      <td>115.678</td>\n",
       "      <td>3830.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>2022-07-04</td>\n",
       "      <td>105.726</td>\n",
       "      <td>912201.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.826</td>\n",
       "      <td>3869.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>2022-07-11</td>\n",
       "      <td>101.284</td>\n",
       "      <td>906758.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.756</td>\n",
       "      <td>3825.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>105.520</td>\n",
       "      <td>896631.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.490</td>\n",
       "      <td>3937.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>101.424</td>\n",
       "      <td>896408.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.229</td>\n",
       "      <td>4022.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>97.278</td>\n",
       "      <td>896568.0</td>\n",
       "      <td>20390.0</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>116.726</td>\n",
       "      <td>4132.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>97.622</td>\n",
       "      <td>886110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.136</td>\n",
       "      <td>4192.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>94.880</td>\n",
       "      <td>874737.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.505</td>\n",
       "      <td>4277.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>2022-08-22</td>\n",
       "      <td>99.254</td>\n",
       "      <td>868344.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.980</td>\n",
       "      <td>4132.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>96.358</td>\n",
       "      <td>869662.0</td>\n",
       "      <td>20420.0</td>\n",
       "      <td>34990.0</td>\n",
       "      <td>119.574</td>\n",
       "      <td>3972.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>91.712</td>\n",
       "      <td>863690.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.440</td>\n",
       "      <td>3990.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>92.692</td>\n",
       "      <td>857932.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.079</td>\n",
       "      <td>3952.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>89.588</td>\n",
       "      <td>853142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.913</td>\n",
       "      <td>3799.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>85.620</td>\n",
       "      <td>845592.0</td>\n",
       "      <td>20660.0</td>\n",
       "      <td>35080.0</td>\n",
       "      <td>124.377</td>\n",
       "      <td>3649.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>93.274</td>\n",
       "      <td>847781.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.578</td>\n",
       "      <td>3727.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>93.826</td>\n",
       "      <td>842492.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.445</td>\n",
       "      <td>3606.248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date     data        d2       d6  d9_lag1      d16       d23\n",
       "842  2022-03-21  114.834  978272.0      NaN      NaN  109.667  4498.444\n",
       "843  2022-03-28  107.548  976951.0  19960.0  33720.0  109.474  4577.168\n",
       "844  2022-04-04  103.720  982434.0      NaN      NaN  110.337  4515.480\n",
       "845  2022-04-11  105.900  969713.0      NaN      NaN  111.216  4412.290\n",
       "846  2022-04-18  108.338  967494.0      NaN      NaN  111.743  4395.758\n",
       "847  2022-04-25  105.224  965712.0  20040.0  34020.0  113.923  4214.942\n",
       "848  2022-05-02  109.196  967208.0      NaN      NaN  114.698  4181.350\n",
       "849  2022-05-09  106.982  958804.0      NaN      NaN  115.524  3976.288\n",
       "850  2022-05-16  111.974  951814.0      NaN      NaN  114.646  3964.538\n",
       "851  2022-05-23  114.148  941325.0      NaN      NaN  113.220  4022.008\n",
       "852  2022-05-30  117.364  936081.0  20350.0  33530.0  113.017  4129.685\n",
       "853  2022-06-06  121.748  930326.0      NaN      NaN  113.753  4063.312\n",
       "854  2022-06-13  118.976  923146.0      NaN      NaN  116.129  3723.342\n",
       "855  2022-06-20  111.934  913434.0      NaN      NaN  115.516  3808.038\n",
       "856  2022-06-27  111.578  915828.0  20550.0  33740.0  115.678  3830.240\n",
       "857  2022-07-04  105.726  912201.0      NaN      NaN  117.826  3869.618\n",
       "858  2022-07-11  101.284  906758.0      NaN      NaN  118.756  3825.710\n",
       "859  2022-07-18  105.520  896631.0      NaN      NaN  117.490  3937.604\n",
       "860  2022-07-25  101.424  896408.0      NaN      NaN  117.229  4022.844\n",
       "861  2022-08-01   97.278  896568.0  20390.0  34000.0  116.726  4132.424\n",
       "862  2022-08-08   97.622  886110.0      NaN      NaN  116.136  4192.038\n",
       "863  2022-08-15   94.880  874737.0      NaN      NaN  117.505  4277.720\n",
       "864  2022-08-22   99.254  868344.0      NaN      NaN  118.980  4132.854\n",
       "865  2022-08-29   96.358  869662.0  20420.0  34990.0  119.574  3972.576\n",
       "866  2022-09-05   91.712  863690.0      NaN      NaN  120.440  3990.400\n",
       "867  2022-09-12   92.692  857932.0      NaN      NaN  120.079  3952.758\n",
       "868  2022-09-19   89.588  853142.0      NaN      NaN  121.913  3799.394\n",
       "869  2022-09-26   85.620  845592.0  20660.0  35080.0  124.377  3649.492\n",
       "870  2022-10-03   93.274  847781.0      NaN      NaN  123.578  3727.364\n",
       "871  2022-10-10   93.826  842492.0      NaN      NaN  124.445  3606.248"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata = pd.read_csv(\"weekly_brentoil_total_df.csv\", encoding='CP949') # (2nd step)\n",
    "dbcode = \"02-01-01-00-02-00-1301-NO\" # (3rd step)\n",
    "\n",
    "# Change this for multivariate time series !\n",
    "add_col = ['d2','d6','d9_lag1','d16','d23'] #['d2','d6','d9_lag1','d16','d23'] #'d2','d6','d9','d16','d23' # (4th step)\n",
    "#add_col=[]\n",
    "output_dim = 1+len(add_col)\n",
    "multi_data = pd.DataFrame(rawdata[['Date','data']+add_col])\n",
    "multi_data.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acc12afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear interpolation (월간 ---> 주간)\n",
    "if len(add_col)>0 :\n",
    "    interpol_li = ['d6','d9_lag1']\n",
    "    for k in interpol_li:\n",
    "        multi_data[k] = multi_data[k].interpolate(method='polynomial', order=1)\n",
    "    multi_data.tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad4e9df",
   "metadata": {},
   "source": [
    "# 중요!  전망 품목 dbcode, search_cols 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56783280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_spec</th>\n",
       "      <th>dbcode</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>전기동</td>\n",
       "      <td>3개월(o)</td>\n",
       "      <td>04-01-02-00-01-00-1302-98</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>팔라듐</td>\n",
       "      <td>현물</td>\n",
       "      <td>01-02-00-00-02-00-1306-95</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>백금</td>\n",
       "      <td>현물</td>\n",
       "      <td>01-02-00-00-01-00-1306-95</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>로듐</td>\n",
       "      <td>현물</td>\n",
       "      <td>01-02-00-00-05-00-2937-00</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>코발트</td>\n",
       "      <td>standard_grade_metal</td>\n",
       "      <td>04-02-00-00-35-32-2364-00</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_name             item_spec                     dbcode  count\n",
       "0       전기동                3개월(o)  04-01-02-00-01-00-1302-98     99\n",
       "1       팔라듐                    현물  01-02-00-00-02-00-1306-95     99\n",
       "2        백금                    현물  01-02-00-00-01-00-1306-95     99\n",
       "3        로듐                    현물  01-02-00-00-05-00-2937-00     99\n",
       "4       코발트  standard_grade_metal  04-02-00-00-35-32-2364-00     99"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_coll2 = db['arima_mth']\n",
    "stats_df = coll_profile(raw_coll2)\n",
    "stats_df.head() #재료 현황"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01429ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_spec</th>\n",
       "      <th>dbcode</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>브렌트유</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02-01-01-00-02-00-1301-NO</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_name item_spec                     dbcode  count\n",
       "57      브렌트유       NaN  02-01-01-00-02-00-1301-NO     99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_li = [dbcode] \n",
    "\n",
    "primary_info = stats_df[stats_df['dbcode'].map(lambda x: x in comm_li)]\n",
    "primary_info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9d5426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02-01-01-00-02-00-1301-NO']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candi_comm = list(primary_info['dbcode']) \n",
    "candi_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2acb8823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('브렌트유', nan): '02-01-01-00-02-00-1301-NO'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_list = dict(zip(primary_info.apply(lambda x: (x['item_name'], x['item_spec']), axis=1), primary_info[\"dbcode\"]))\n",
    "item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805afbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'브렌트유'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(item_list)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d669a5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(item_list)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "249b8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(add_col) > 0:\n",
    "    if list(item_list)[0][0] == '브렌트유' :\n",
    "        search_cols = ['02-03-01-E2-01-00-USA-00-57-05', '02-01-01-ED-00-00-USA-00-57-04',\n",
    "    '02-01-01-ED-00-00-922-00-57-04', '01-02-02-03-00-05-USA-00-19-06',\n",
    "    '2_01_03_03_03_00_05_USA_00_134_06']\n",
    "\n",
    "    elif list(item_list)[0][0] == '철광석 Fines' :\n",
    "        search_cols = ['01-01-05-54-08-02-CHN-00-184-04',\n",
    "                                '02-03-01-VG-01-00-CHN-00-132-04',\n",
    "                                '01-03-02-01-02-02-CHN-00-71-04',\n",
    "                                '01-03-01-19-00-02-CHN-00-71-06']\n",
    "else:\n",
    "    search_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07159696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02-03-01-E2-01-00-USA-00-57-05',\n",
       " '02-01-01-ED-00-00-USA-00-57-04',\n",
       " '02-01-01-ED-00-00-922-00-57-04',\n",
       " '01-02-02-03-00-05-USA-00-19-06',\n",
       " '2_01_03_03_03_00_05_USA_00_134_06']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60d9b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_doc_def =  {\"model_type\": \"TRANSFORMER\", \"model_writer\": \"KMS\", \"ensemble\": False,\n",
    "              \"reg_date\": to_datetime(datetime.date.today()),\"model_para\": {'freq': 'W', 'package': 'pytorch', 'dat_trans': 'log return', 'input_len':enc_len, 'output_len':pred_len},\n",
    "             \"item_name\": list(item_list)[0][0], \"item_spec\": list(item_list)[0][1], \"dbcode\": dbcode, \n",
    "             \"search_cols\": search_cols}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6edbbe",
   "metadata": {},
   "source": [
    "## 트랜스포머 전망치 업데이트 및 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3e666a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 12:56:59,806]\u001b[0m A new study created in memory with name: no-name-0c894c49-f518-44cb-acd2-876a68d03358\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 모델 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 12:57:39,524]\u001b[0m Trial 0 finished with value: 5.782409683744348 and parameters: {'learning_rate': 0.04445118375610763, 'optimizer': 'RMSprop', 'batch_size': 32, 'd_model': 256, 'nhead': 4, 'nhid': 256, 'nlayers': 2, 'label_len': 0}. Best is trial 0 with value: 5.782409683744348.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 12:58:26,167]\u001b[0m Trial 1 finished with value: 3.375126633691052 and parameters: {'learning_rate': 0.0676437187588595, 'optimizer': 'Adam', 'batch_size': 32, 'd_model': 256, 'nhead': 8, 'nhid': 512, 'nlayers': 2, 'label_len': 8}. Best is trial 1 with value: 3.375126633691052.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:02:11,725]\u001b[0m Trial 2 finished with value: 3.3692901034711995 and parameters: {'learning_rate': 0.02258015820628709, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 512, 'nhead': 8, 'nhid': 512, 'nlayers': 4, 'label_len': 8}. Best is trial 2 with value: 3.3692901034711995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:04:12,787]\u001b[0m Trial 3 finished with value: 4.982901576410565 and parameters: {'learning_rate': 0.047509628736035404, 'optimizer': 'RMSprop', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 512, 'nlayers': 4, 'label_len': 12}. Best is trial 2 with value: 3.3692901034711995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:04:53,752]\u001b[0m Trial 4 finished with value: 4.113808429670062 and parameters: {'learning_rate': 0.014813115750159431, 'optimizer': 'SGD', 'batch_size': 32, 'd_model': 256, 'nhead': 4, 'nhid': 256, 'nlayers': 2, 'label_len': 8}. Best is trial 2 with value: 3.3692901034711995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:04:54,974]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:06:10,229]\u001b[0m Trial 6 finished with value: 4.336649757606184 and parameters: {'learning_rate': 0.08281584311957166, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 256, 'nhead': 8, 'nhid': 256, 'nlayers': 2, 'label_len': 8}. Best is trial 2 with value: 3.3692901034711995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:06:11,287]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:07:28,053]\u001b[0m Trial 8 finished with value: 4.456284821232973 and parameters: {'learning_rate': 0.06502097645025776, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 512, 'nlayers': 2, 'label_len': 8}. Best is trial 2 with value: 3.3692901034711995.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:07:37,649]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:07:42,226]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:07:44,497]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:08:14,306]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:08:16,520]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:08:20,812]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:08:45,835]\u001b[0m A new study created in memory with name: no-name-7a991b22-98df-40b6-8fb7-7032374b85e3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번째 모델 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 13:10:14,402]\u001b[0m Trial 0 finished with value: 3.7227070069438906 and parameters: {'learning_rate': 0.07470299746417307, 'optimizer': 'SGD', 'batch_size': 32, 'd_model': 512, 'nhead': 8, 'nhid': 256, 'nlayers': 2, 'label_len': 0}. Best is trial 0 with value: 3.7227070069438906.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:11:35,605]\u001b[0m Trial 1 finished with value: 5.743956873444077 and parameters: {'learning_rate': 0.07194687942262352, 'optimizer': 'RMSprop', 'batch_size': 32, 'd_model': 256, 'nhead': 4, 'nhid': 512, 'nlayers': 4, 'label_len': 4}. Best is trial 0 with value: 3.7227070069438906.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:12:54,013]\u001b[0m Trial 2 finished with value: 3.3877410875913267 and parameters: {'learning_rate': 0.013140203496156603, 'optimizer': 'Adam', 'batch_size': 32, 'd_model': 256, 'nhead': 4, 'nhid': 256, 'nlayers': 4, 'label_len': 4}. Best is trial 2 with value: 3.3877410875913267.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:16:29,266]\u001b[0m Trial 3 finished with value: 4.562139835328108 and parameters: {'learning_rate': 0.059035564105124734, 'optimizer': 'Adam', 'batch_size': 32, 'd_model': 512, 'nhead': 8, 'nhid': 512, 'nlayers': 4, 'label_len': 12}. Best is trial 2 with value: 3.3877410875913267.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:20:12,649]\u001b[0m Trial 4 finished with value: 3.5411208967801984 and parameters: {'learning_rate': 0.029596124755192948, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 512, 'nhead': 4, 'nhid': 512, 'nlayers': 4, 'label_len': 8}. Best is trial 2 with value: 3.3877410875913267.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:20:13,685]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:20:14,156]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:20:14,587]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:20:15,703]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:20:21,624]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:22:38,263]\u001b[0m Trial 10 finished with value: 3.9439825100554757 and parameters: {'learning_rate': 0.001491997120364054, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 256, 'nhead': 8, 'nhid': 256, 'nlayers': 4, 'label_len': 12}. Best is trial 2 with value: 3.3877410875913267.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:22:59,108]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:23:00,677]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:23:03,249]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:23:04,725]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:23:41,647]\u001b[0m A new study created in memory with name: no-name-2a42547e-b20c-4377-ba32-5ecb0b6b947e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번째 모델 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 13:24:50,434]\u001b[0m Trial 0 finished with value: 5.491996706904705 and parameters: {'learning_rate': 0.03420806286712165, 'optimizer': 'RMSprop', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 512, 'nlayers': 2, 'label_len': 12}. Best is trial 0 with value: 5.491996706904705.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:26:36,478]\u001b[0m Trial 1 finished with value: 3.2366453015041947 and parameters: {'learning_rate': 0.05342957554566468, 'optimizer': 'SGD', 'batch_size': 16, 'd_model': 512, 'nhead': 4, 'nhid': 256, 'nlayers': 2, 'label_len': 12}. Best is trial 1 with value: 3.2366453015041947.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:29:58,057]\u001b[0m Trial 2 finished with value: 3.5059857446315004 and parameters: {'learning_rate': 0.0120277873403853, 'optimizer': 'SGD', 'batch_size': 16, 'd_model': 512, 'nhead': 8, 'nhid': 512, 'nlayers': 4, 'label_len': 0}. Best is trial 1 with value: 3.2366453015041947.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:30:55,640]\u001b[0m Trial 3 finished with value: 3.8044897085955003 and parameters: {'learning_rate': 0.06754150324559284, 'optimizer': 'SGD', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 256, 'nlayers': 2, 'label_len': 8}. Best is trial 1 with value: 3.2366453015041947.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:32:02,779]\u001b[0m Trial 4 finished with value: 5.636541982763962 and parameters: {'learning_rate': 0.07928440396270454, 'optimizer': 'RMSprop', 'batch_size': 16, 'd_model': 256, 'nhead': 8, 'nhid': 256, 'nlayers': 2, 'label_len': 0}. Best is trial 1 with value: 3.2366453015041947.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:32:05,051]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:32:06,216]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:32:08,494]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:32:55,194]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:32:59,728]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:33:01,727]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:33:04,039]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:33:10,784]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:33:13,051]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:33:15,261]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:33:50,209]\u001b[0m A new study created in memory with name: no-name-9660892c-bdac-4c44-ad08-63550f8b95c2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번째 모델 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 13:35:53,697]\u001b[0m Trial 0 finished with value: 3.6241160822586536 and parameters: {'learning_rate': 0.09345523519855278, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 512, 'nhead': 8, 'nhid': 512, 'nlayers': 2, 'label_len': 12}. Best is trial 0 with value: 3.6241160822586536.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:37:26,597]\u001b[0m Trial 1 finished with value: 3.476471030278004 and parameters: {'learning_rate': 0.09223979677297399, 'optimizer': 'SGD', 'batch_size': 32, 'd_model': 512, 'nhead': 4, 'nhid': 256, 'nlayers': 2, 'label_len': 4}. Best is trial 1 with value: 3.476471030278004.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:40:55,103]\u001b[0m Trial 2 finished with value: 5.233596908995995 and parameters: {'learning_rate': 0.04798316078760515, 'optimizer': 'RMSprop', 'batch_size': 32, 'd_model': 512, 'nhead': 8, 'nhid': 512, 'nlayers': 4, 'label_len': 4}. Best is trial 1 with value: 3.476471030278004.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:42:35,840]\u001b[0m Trial 3 finished with value: 3.7257819214008 and parameters: {'learning_rate': 0.05623115900159656, 'optimizer': 'SGD', 'batch_size': 32, 'd_model': 512, 'nhead': 4, 'nhid': 512, 'nlayers': 2, 'label_len': 0}. Best is trial 1 with value: 3.476471030278004.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:44:30,915]\u001b[0m Trial 4 finished with value: 3.5987335592014134 and parameters: {'learning_rate': 0.08437815110775916, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 512, 'nhead': 8, 'nhid': 512, 'nlayers': 2, 'label_len': 4}. Best is trial 1 with value: 3.476471030278004.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:44:39,194]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:44:47,286]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:44:48,488]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:44:49,495]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:45:08,624]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:45:11,573]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:45:12,773]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:46:57,101]\u001b[0m Trial 12 finished with value: 4.259565573963264 and parameters: {'learning_rate': 0.08341163706135367, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 512, 'nhead': 4, 'nhid': 256, 'nlayers': 2, 'label_len': 0}. Best is trial 1 with value: 3.476471030278004.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:47:00,470]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:47:01,493]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:47:37,032]\u001b[0m A new study created in memory with name: no-name-5d53349c-5f87-4e20-be6c-7e91d16cd59d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5번째 모델 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 13:49:34,549]\u001b[0m Trial 0 finished with value: 3.706394500261752 and parameters: {'learning_rate': 0.03318991742504379, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 512, 'nhead': 4, 'nhid': 512, 'nlayers': 2, 'label_len': 12}. Best is trial 0 with value: 3.706394500261752.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:51:44,697]\u001b[0m Trial 1 finished with value: 4.144754353402177 and parameters: {'learning_rate': 0.08139652743940827, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 256, 'nhead': 8, 'nhid': 256, 'nlayers': 4, 'label_len': 0}. Best is trial 0 with value: 3.706394500261752.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:53:54,258]\u001b[0m Trial 2 finished with value: 4.094625395622272 and parameters: {'learning_rate': 0.0832375049345274, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 256, 'nlayers': 4, 'label_len': 4}. Best is trial 0 with value: 3.706394500261752.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:56:56,762]\u001b[0m Trial 3 finished with value: 4.043107832834217 and parameters: {'learning_rate': 0.05707508806167309, 'optimizer': 'SGD', 'batch_size': 32, 'd_model': 512, 'nhead': 4, 'nhid': 256, 'nlayers': 4, 'label_len': 12}. Best is trial 0 with value: 3.706394500261752.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:58:53,799]\u001b[0m Trial 4 finished with value: 3.375052337673909 and parameters: {'learning_rate': 0.006829553328095558, 'optimizer': 'RMSprop', 'batch_size': 16, 'd_model': 256, 'nhead': 8, 'nhid': 512, 'nlayers': 4, 'label_len': 4}. Best is trial 4 with value: 3.375052337673909.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:58:54,306]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:58:56,632]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:58:57,332]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:58:59,664]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:59:00,711]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 13:59:01,615]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:02:50,863]\u001b[0m Trial 11 finished with value: 3.8368508022870373 and parameters: {'learning_rate': 0.027545918337664874, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 512, 'nhead': 8, 'nhid': 512, 'nlayers': 4, 'label_len': 12}. Best is trial 4 with value: 3.375052337673909.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:02:52,402]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:02:54,792]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:02:56,353]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:03:36,410]\u001b[0m A new study created in memory with name: no-name-51aa76a7-ee84-43a5-9f05-0016f920c42a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6번째 모델 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 14:04:34,609]\u001b[0m Trial 0 finished with value: 3.941174966405768 and parameters: {'learning_rate': 0.04587257744278338, 'optimizer': 'SGD', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 256, 'nlayers': 2, 'label_len': 8}. Best is trial 0 with value: 3.941174966405768.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:06:30,685]\u001b[0m Trial 1 finished with value: 4.438527539052388 and parameters: {'learning_rate': 0.08639446045478241, 'optimizer': 'RMSprop', 'batch_size': 16, 'd_model': 512, 'nhead': 8, 'nhid': 512, 'nlayers': 2, 'label_len': 12}. Best is trial 0 with value: 3.941174966405768.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:08:15,645]\u001b[0m Trial 2 finished with value: 4.040681814609826 and parameters: {'learning_rate': 0.06334049819701, 'optimizer': 'Adam', 'batch_size': 32, 'd_model': 512, 'nhead': 4, 'nhid': 512, 'nlayers': 2, 'label_len': 4}. Best is trial 0 with value: 3.941174966405768.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:10:14,994]\u001b[0m Trial 3 finished with value: 5.499697147616867 and parameters: {'learning_rate': 0.045624284913402924, 'optimizer': 'RMSprop', 'batch_size': 16, 'd_model': 256, 'nhead': 8, 'nhid': 512, 'nlayers': 4, 'label_len': 12}. Best is trial 0 with value: 3.941174966405768.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:13:21,310]\u001b[0m Trial 4 finished with value: 4.426834970025621 and parameters: {'learning_rate': 0.07646535563762043, 'optimizer': 'RMSprop', 'batch_size': 32, 'd_model': 512, 'nhead': 8, 'nhid': 256, 'nlayers': 4, 'label_len': 8}. Best is trial 0 with value: 3.941174966405768.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:13:37,533]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:13:38,966]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:13:40,841]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:13:41,337]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:13:45,216]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:13:49,968]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:13:53,544]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:15:08,702]\u001b[0m Trial 12 finished with value: 4.698175335772247 and parameters: {'learning_rate': 0.05891922032107697, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 512, 'nlayers': 2, 'label_len': 0}. Best is trial 0 with value: 3.941174966405768.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:15:15,226]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:15:19,488]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:15:54,263]\u001b[0m A new study created in memory with name: no-name-f4299cef-0be7-4188-8ad7-7018eb8a1e56\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번째 모델 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 14:17:18,234]\u001b[0m Trial 0 finished with value: 3.3688793808249797 and parameters: {'learning_rate': 0.0011481412495665721, 'optimizer': 'Adam', 'batch_size': 32, 'd_model': 256, 'nhead': 8, 'nhid': 256, 'nlayers': 4, 'label_len': 8}. Best is trial 0 with value: 3.3688793808249797.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:20:58,828]\u001b[0m Trial 1 finished with value: 4.373212171564696 and parameters: {'learning_rate': 0.06617578830133766, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 512, 'nhead': 4, 'nhid': 256, 'nlayers': 4, 'label_len': 12}. Best is trial 0 with value: 3.3688793808249797.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:22:52,987]\u001b[0m Trial 2 finished with value: 4.012525446185556 and parameters: {'learning_rate': 0.0910638846771509, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 512, 'nhead': 4, 'nhid': 512, 'nlayers': 2, 'label_len': 0}. Best is trial 0 with value: 3.3688793808249797.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:26:04,093]\u001b[0m Trial 3 finished with value: 5.626802240671956 and parameters: {'learning_rate': 0.008839337691920756, 'optimizer': 'SGD', 'batch_size': 32, 'd_model': 512, 'nhead': 8, 'nhid': 256, 'nlayers': 4, 'label_len': 12}. Best is trial 0 with value: 3.3688793808249797.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:27:50,874]\u001b[0m Trial 4 finished with value: 3.435228531908386 and parameters: {'learning_rate': 0.0797052545715382, 'optimizer': 'SGD', 'batch_size': 16, 'd_model': 512, 'nhead': 4, 'nhid': 256, 'nlayers': 2, 'label_len': 12}. Best is trial 0 with value: 3.3688793808249797.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:27:54,852]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:27:56,029]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:27:58,137]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:27:59,345]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:28:00,019]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:28:05,442]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:28:05,914]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:28:06,803]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:28:09,221]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:28:09,704]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:28:47,170]\u001b[0m A new study created in memory with name: no-name-b0b350e2-4c15-4843-95ef-1439a80cd784\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8번째 모델 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 14:30:41,185]\u001b[0m Trial 0 finished with value: 5.601791617656256 and parameters: {'learning_rate': 0.0848497974637443, 'optimizer': 'RMSprop', 'batch_size': 16, 'd_model': 256, 'nhead': 8, 'nhid': 256, 'nlayers': 4, 'label_len': 8}. Best is trial 0 with value: 5.601791617656256.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:32:33,824]\u001b[0m Trial 1 finished with value: 3.784502783336675 and parameters: {'learning_rate': 0.08940250395344829, 'optimizer': 'SGD', 'batch_size': 16, 'd_model': 512, 'nhead': 8, 'nhid': 512, 'nlayers': 2, 'label_len': 8}. Best is trial 1 with value: 3.784502783336675.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:35:55,099]\u001b[0m Trial 2 finished with value: 3.837687035891103 and parameters: {'learning_rate': 0.07861634460273519, 'optimizer': 'SGD', 'batch_size': 16, 'd_model': 512, 'nhead': 8, 'nhid': 256, 'nlayers': 4, 'label_len': 8}. Best is trial 1 with value: 3.784502783336675.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:39:38,117]\u001b[0m Trial 3 finished with value: 3.9409025018652364 and parameters: {'learning_rate': 0.014961804527705415, 'optimizer': 'RMSprop', 'batch_size': 16, 'd_model': 512, 'nhead': 8, 'nhid': 512, 'nlayers': 4, 'label_len': 12}. Best is trial 1 with value: 3.784502783336675.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:43:00,799]\u001b[0m Trial 4 finished with value: 5.710387403700729 and parameters: {'learning_rate': 0.03941298242501143, 'optimizer': 'RMSprop', 'batch_size': 32, 'd_model': 512, 'nhead': 8, 'nhid': 512, 'nlayers': 4, 'label_len': 4}. Best is trial 1 with value: 3.784502783336675.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:43:04,724]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:43:13,385]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:45:26,852]\u001b[0m Trial 7 finished with value: 3.3708430891577845 and parameters: {'learning_rate': 0.028363548653496107, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 512, 'nlayers': 4, 'label_len': 12}. Best is trial 7 with value: 3.3708430891577845.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:45:30,852]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:45:32,043]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:45:32,980]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:46:47,678]\u001b[0m Trial 11 finished with value: 4.710987371863609 and parameters: {'learning_rate': 0.05625999137861656, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 512, 'nlayers': 2, 'label_len': 12}. Best is trial 7 with value: 3.3708430891577845.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:46:48,486]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:46:50,935]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:46:51,452]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:47:30,407]\u001b[0m A new study created in memory with name: no-name-41b90aa4-87b9-4af0-920e-53e057570a7d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9번째 모델 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 14:48:34,728]\u001b[0m Trial 0 finished with value: 5.54678032132261 and parameters: {'learning_rate': 0.07301699973132858, 'optimizer': 'RMSprop', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 256, 'nlayers': 2, 'label_len': 4}. Best is trial 0 with value: 5.54678032132261.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:50:08,774]\u001b[0m Trial 1 finished with value: 3.381445268473577 and parameters: {'learning_rate': 0.0013306403273378278, 'optimizer': 'Adam', 'batch_size': 32, 'd_model': 512, 'nhead': 4, 'nhid': 256, 'nlayers': 2, 'label_len': 4}. Best is trial 1 with value: 3.381445268473577.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:53:43,033]\u001b[0m Trial 2 finished with value: 3.829763190598714 and parameters: {'learning_rate': 0.022302525915908353, 'optimizer': 'SGD', 'batch_size': 16, 'd_model': 512, 'nhead': 4, 'nhid': 512, 'nlayers': 4, 'label_len': 12}. Best is trial 1 with value: 3.381445268473577.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:55:28,665]\u001b[0m Trial 3 finished with value: 3.828221860525423 and parameters: {'learning_rate': 0.08577733489832713, 'optimizer': 'SGD', 'batch_size': 16, 'd_model': 512, 'nhead': 8, 'nhid': 256, 'nlayers': 2, 'label_len': 8}. Best is trial 1 with value: 3.381445268473577.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:56:45,392]\u001b[0m Trial 4 finished with value: 3.4096505423883774 and parameters: {'learning_rate': 0.04379052577074933, 'optimizer': 'Adam', 'batch_size': 32, 'd_model': 256, 'nhead': 4, 'nhid': 256, 'nlayers': 4, 'label_len': 4}. Best is trial 1 with value: 3.381445268473577.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:56:56,123]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:56:58,878]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:58:12,657]\u001b[0m Trial 7 finished with value: 4.4606191705647324 and parameters: {'learning_rate': 0.052876386124215004, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 512, 'nlayers': 2, 'label_len': 4}. Best is trial 1 with value: 3.381445268473577.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:58:13,116]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:58:14,228]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:58:16,161]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:58:17,021]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:58:17,858]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:58:19,728]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:58:20,616]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 14:58:54,744]\u001b[0m A new study created in memory with name: no-name-f2a5425f-aa64-4b49-8f14-4606288bed37\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10번째 모델 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-21 14:59:52,591]\u001b[0m Trial 0 finished with value: 3.863444087787212 and parameters: {'learning_rate': 0.02389636184900816, 'optimizer': 'SGD', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 256, 'nlayers': 2, 'label_len': 4}. Best is trial 0 with value: 3.863444087787212.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:03:16,285]\u001b[0m Trial 1 finished with value: 5.842479525500855 and parameters: {'learning_rate': 0.09830674705074995, 'optimizer': 'RMSprop', 'batch_size': 16, 'd_model': 512, 'nhead': 8, 'nhid': 256, 'nlayers': 4, 'label_len': 4}. Best is trial 0 with value: 3.863444087787212.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:04:59,094]\u001b[0m Trial 2 finished with value: 3.964534586591219 and parameters: {'learning_rate': 0.011493323749551823, 'optimizer': 'SGD', 'batch_size': 16, 'd_model': 256, 'nhead': 4, 'nhid': 256, 'nlayers': 4, 'label_len': 0}. Best is trial 0 with value: 3.863444087787212.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:07:13,149]\u001b[0m Trial 3 finished with value: 4.481982129600493 and parameters: {'learning_rate': 0.05547398604999056, 'optimizer': 'Adam', 'batch_size': 16, 'd_model': 256, 'nhead': 8, 'nhid': 256, 'nlayers': 4, 'label_len': 4}. Best is trial 0 with value: 3.863444087787212.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:07:57,958]\u001b[0m Trial 4 finished with value: 3.2573892145999657 and parameters: {'learning_rate': 0.06968012374003507, 'optimizer': 'SGD', 'batch_size': 32, 'd_model': 256, 'nhead': 8, 'nhid': 512, 'nlayers': 2, 'label_len': 0}. Best is trial 4 with value: 3.2573892145999657.\u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:07:58,727]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:07:59,624]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:08:00,103]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:08:01,037]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:08:01,516]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:08:02,619]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:08:08,129]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:08:09,956]\u001b[0m Trial 12 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:08:10,455]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-02-21 15:08:11,607]\u001b[0m Trial 14 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from datetime import date\n",
    "real_y = copy.deepcopy(multi_data[['Date','data']])\n",
    "real_y['Date'] = real_y['Date'].map(lambda x: date.fromisoformat(x))\n",
    "\n",
    "train_y = real_y[real_y['Date']>= date.fromisoformat('2010-01-01')] #start of valid\n",
    "train_y = train_y[train_y['Date'] <= date.fromisoformat('2020-06-30')] #end of valid\n",
    "\n",
    "valid_y = real_y[real_y['Date']>= date.fromisoformat('2020-07-01')] #start of valid\n",
    "valid_y = valid_y[valid_y['Date'] <= date.fromisoformat('2021-06-30')] #end of valid\n",
    "\n",
    "for i in list(multi_data.columns)[1:]:\n",
    "    multi_data[i] = np.log(multi_data[i]).diff(1)\n",
    "\n",
    "multi_data['Date'] = multi_data['Date'].map(lambda x: date.fromisoformat(x))\n",
    "\n",
    "import copy\n",
    "train_valid = copy.deepcopy(multi_data[multi_data['Date']>= date.fromisoformat('2010-01-01')]) #start of train\n",
    "train_valid = train_valid[train_valid['Date'] <= date.fromisoformat('2021-06-30')] #end of valid\n",
    "\n",
    "min_y  = np.array(train_valid['data']).min()\n",
    "max_y  = np.array(train_valid['data']).max()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "train_valid = min_max_scaler.fit_transform(train_valid[['data']+add_col]) #train+valid 스케일링\n",
    "multi_data_sc = min_max_scaler.transform(multi_data[['data']+add_col]) #스케일링된 total 데이터프레임\n",
    "\n",
    "multi_data[['data']+add_col] = pd.DataFrame(multi_data_sc,columns=['data']+add_col)\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "#multi_data['Date'] = multi_data['Date'].map(lambda x: date.fromisoformat(x))\n",
    "\n",
    "train = multi_data[multi_data['Date']>= date.fromisoformat('2010-01-01')] #start of train\n",
    "train = train[train['Date'] <= date.fromisoformat('2020-06-30')] #end of train\n",
    "\n",
    "valid = multi_data[multi_data['Date']>= date.fromisoformat('2020-07-01')] #start of valid\n",
    "valid = valid[valid['Date'] <= date.fromisoformat('2021-06-30')] #end of valid\n",
    "\n",
    "test = multi_data[multi_data['Date']>= date.fromisoformat('2021-07-01')] #start of test\n",
    "test = test[test['Date'] <= date.fromisoformat('2022-06-30')] #end of test\n",
    "\n",
    "total = multi_data[multi_data['Date']>= date.fromisoformat('2010-01-01')] #start of total = start of train\n",
    "total = total[total['Date'] <= date.fromisoformat('2022-06-30')] #end of total = end of test\n",
    "\n",
    "data_train = train[['data']+add_col].to_numpy()\n",
    "data_valid = valid[['data']+add_col].to_numpy()\n",
    "data_test = test[['data']+add_col].to_numpy()\n",
    "data_total = total[['data']+add_col].to_numpy()\n",
    "\n",
    "## 주의할것! ##\n",
    "data_valid = np.concatenate([data_train[-enc_len:,],data_valid]) #windowDataset 함수에 넣기전에 enc_len개의 이전값 추가 \n",
    "data_valid = np.concatenate([data_valid, np.zeros([pred_len,output_dim])]) #windowDataset 함수에 넣기전에 pred_len개의 0을 추가(valid_1m_mape 계산을 위해서)\n",
    "\n",
    "add_len = enc_len+pred_len\n",
    "data_test = np.concatenate([data_valid[-add_len:-pred_len,],data_test]) #windowDataset 함수에 넣기전에 enc_len개의 이전값 추가 (수정된 data_valid로 부터...)\n",
    "data_test = np.concatenate([data_test, np.zeros([pred_len,output_dim])]) #windowDataset 함수에 넣기전에 pred_len개의 0을 추가(test_1m_mape 계산을 위해서)\n",
    "\n",
    "import optuna\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "model = TFModel(d_model, nhead, nhid, nlayers, output_dim, dropout).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = None\n",
    "\n",
    "# EPOCHS early stopping\n",
    "patience = 3\n",
    "min_delta = 10\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# Full code implementation of define-by-run and pruning mechanism\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Build a model by implementing define-by-run design from Optuna\n",
    "def build_model_custom(param,trial):    \n",
    "\n",
    "    # 향후에 TFModel의 구조 자체도 tuning하고 싶다면 기초 단계에서부터 짜는 방법을 이 함수에 포함시켜야 할 것으로 보임\n",
    "    # Transformer는 layer 단위의 structure를 바꾸기 보다는 d_model, nhead와 같이 이미 주어진 paramter를 조정하는 것이 필요해 보임\n",
    "\n",
    "\n",
    "    d_model = param['d_model']\n",
    "    nhead = param['nhead']\n",
    "    nhid = param['nhid']\n",
    "    nlayers = param['nlayers'] # params['nlayers']\n",
    "    dropout = 0.1\n",
    "\n",
    "    model = TFModel(d_model, nhead, nhid, nlayers, output_dim, dropout).to(device)\n",
    "\n",
    "    \"\"\"\n",
    "    만약에 model의 parameter값도 tuning하고 싶다면 \n",
    "    nlayers = trial.suggest_int(\"nlayers\", 2, 4)과 같이 작성하면 될 것으로 보임  \n",
    "    \"\"\"\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Train and evaluate the accuracy of neural network with the addition of pruning mechanism\n",
    "def train_and_evaluate(param, model, trial, enc_len, pred_len):\n",
    "\n",
    "    label_len = param['label_len']\n",
    "    stride = 1\n",
    "\n",
    "    data_train = train[['data']+add_col].to_numpy()\n",
    "    data_valid = valid[['data']+add_col].to_numpy()\n",
    "    data_test = test[['data']+add_col].to_numpy()\n",
    "    data_total = total[['data']+add_col].to_numpy()\n",
    "\n",
    "## 주의할것! ##\n",
    "    data_valid = np.concatenate([data_train[-enc_len:,],data_valid]) #windowDataset 함수에 넣기전에 enc_len개의 이전값 추가 \n",
    "    data_valid = np.concatenate([data_valid, np.zeros([pred_len,output_dim])]) #windowDataset 함수에 넣기전에 pred_len개의 0을 추가(valid_1m_mape 계산을 위해서)\n",
    "\n",
    "    add_len = enc_len+pred_len\n",
    "    data_test = np.concatenate([data_valid[-add_len:-pred_len,],data_test]) #windowDataset 함수에 넣기전에 enc_len개의 이전값 추가 (수정된 data_valid로 부터...)\n",
    "    data_test = np.concatenate([data_test, np.zeros([pred_len,output_dim])]) #windowDataset 함수에 넣기전에 pred_len개의 0을 추가(test_1m_mape 계산을 위해서)\n",
    "\n",
    "\n",
    "    # batch_size를 조정하기 위해서는 train_loader, validation_loader를 따로 맞춰서 가져와야 함 \n",
    "    train_dataset = windowDataset(data_train, enc_len = enc_len, pred_len = pred_len, label_len = param['label_len'], output_dim = output_dim, stride = stride)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=param['batch_size'])\n",
    "\n",
    "    valid_dataset = windowDataset(data_valid, enc_len = enc_len, pred_len = pred_len, label_len = param['label_len'], output_dim = output_dim, stride = stride)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=param['batch_size'])\n",
    "\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \"\"\"\n",
    "    getattr은 class의 named attribute 값을 반환함 -> 여기서는 optim이라는 torch 모듈의 param['optimizer']의 값들(optimizing할 수\n",
    "    있는 paramter들의 이름을 반환함)\n",
    "    그러므로 밑에 나와 있는 params들의 \"Adam\", \"RMSprop\", \"SGD\" 방법에 대한 테스트를 모두 진행할 수 있게 됨\n",
    "    그리고 initial learning rate을 아래와 같이 optimizer에 param['learning_rate']으로 지정해 줌에 따라 \n",
    "    learning rate도 튜닝 됨\n",
    "    \"\"\"\n",
    "    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr= param['learning_rate'])\n",
    "\n",
    "    # learning rate scheduler를 지정해서 training하면서 learning rate을 update하도록 함\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "    best_valid_loss = float('inf') #changeable!\n",
    "    best_valid_1m_mape = float('inf')\n",
    "    best_model = None\n",
    "    # Early stopping 사용\n",
    "    early_stopper = EarlyStopper(patience=patience, min_delta=min_delta)\n",
    "\n",
    "    # EPOCHS의 경우 max EPOCHS는 사전에 정해준 값으로 정해지나 prune 방법을 통해 도중에 멈출수 있도록 설계함\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        TF_train(model, train_loader, optimizer, log_interval = 4, scheduler = scheduler, label_len=label_len, epoch=epoch, verbose=False)\n",
    "        train_loss, train_1m_mape = TF_evaluate(model, train_loader, label_len=label_len)\n",
    "        valid_loss, valid_1m_mape = TF_evaluate(model, valid_loader, label_len=label_len)\n",
    "        if epoch%120 ==0:\n",
    "            print(\"[EPOCH: {}], \\tValid Loss: {:.4f}, \\tValid Mape: {:.4f} \\n\".format(\n",
    "                epoch, valid_loss, valid_1m_mape))\n",
    "        #print(\"best_valid_1m_mape: \",best_valid_1m_mape)\n",
    "\n",
    "\n",
    "        # Add prune mechanism\n",
    "        trial.report(valid_loss, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        if valid_1m_mape < best_valid_1m_mape:\n",
    "            best_valid_1m_mape = copy.deepcopy(valid_1m_mape)\n",
    "            best_valid_loss = copy.deepcopy(valid_loss)\n",
    "            best_model = copy.deepcopy(model)\n",
    "            #print(\"best_valid_1m_mape: \",best_valid_1m_mape)\n",
    "\n",
    "        # 여기서는 이렇게 추가하는게 맞는지 의논 필요!!!\n",
    "        if early_stopper.early_stop(valid_loss):             \n",
    "            break\n",
    "\n",
    "\n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "\n",
    "    model = copy.deepcopy(best_model) #매 조합 별 최적의 valid_1m_mape를 갖는 model 갱신\n",
    "\n",
    "\n",
    "    return best_valid_1m_mape #best_valid_1m_mape #valid_loss (optional)\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Define a set of hyperparameter values, build the model, train the model, and evaluate the accuracy\n",
    "def objective(trial):\n",
    "    \n",
    "    global enc_len\n",
    "    global pred_len\n",
    "    #print(\"enc_len:\", enc_len)\n",
    "    #print(\"pred_len:\", pred_len)\n",
    "\n",
    "    params = {\n",
    "              'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "              'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\",\"SGD\",\"RMSprop\"]), \n",
    "                'batch_size': trial.suggest_int('batch_size', 16, 32, step = 16),\n",
    "                'd_model':trial.suggest_int('d_model', 256, 512, step = 256),\n",
    "                'nhead':trial.suggest_int('nhead',4,8,step=4),\n",
    "                'nhid':trial.suggest_int('nhid',256,512,step=256),\n",
    "                'nlayers':trial.suggest_int('nlayers',2,4,step=2),\n",
    "                'label_len':trial.suggest_int('label_len',0,12,step=4)\n",
    "              }\n",
    "\n",
    "    model = build_model_custom(params,trial)\n",
    "\n",
    "    valid_loss = train_and_evaluate(params, model, trial, enc_len = enc_len, pred_len = pred_len)\n",
    "\n",
    "    # Save a trained model to a file.\n",
    "    with open(\"{}.pickle\".format(trial.number), \"wb\") as fout:\n",
    "        pickle.dump(model, fout)\n",
    "\n",
    "    return valid_loss\n",
    "\n",
    "\n",
    "\n",
    "###############################################  모델 리서치서버 업데이트 ################################################\n",
    "\n",
    "total_y = pd.concat([train_y,valid_y])\n",
    "\n",
    "data_total = np.concatenate([data_total, np.zeros([pred_len,output_dim])]) #windowDataset 함수에 넣기전에 pred_len개의 0을 추가(test_1m_mape 계산을 위해서)\n",
    "\n",
    "\n",
    "for p in range(10):\n",
    "    print(str(p+1)+\"번째 모델 시작\")\n",
    "\n",
    "    # Instantiate study session\n",
    "    # Since our objective is to minimize loss function, set direction as minimize\n",
    "    # sampler value indicates which sampler method you want Optuna to implement -> EX) GridSampler, RandomSampler, TPESampler (Bayesian)    \n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=15)\n",
    "    best_trial = study.best_trial\n",
    "    optim_label_len = best_trial.params['label_len'] ###'label_len' 참조해서 입력할것!!\n",
    "\n",
    "    # Load the best model.\n",
    "    with open(\"{}.pickle\".format(study.best_trial.number), \"rb\") as fin:\n",
    "        best_model = pickle.load(fin)\n",
    "\n",
    "    import copy\n",
    "    model = copy.deepcopy(best_model).to(device)\n",
    "\n",
    "    #torch.cuda.empty_cache() #메모리 정리 1\n",
    "\n",
    "    ##### 전기간(pred_date : 2011-12-26 ~ 2022-06-27) 전망치 저장 및 update\n",
    "    total_y = real_y[real_y['Date']>= date.fromisoformat('2012-01-02')] #start of test\n",
    "    total_y = total_y[total_y['Date'] <= date.fromisoformat('2022-06-30')] #end of test\n",
    "\n",
    "    total_dataset = windowDataset(data_total, enc_len = enc_len, pred_len = pred_len, label_len = optim_label_len, output_dim = output_dim, stride = stride)\n",
    "    total_loader = DataLoader(total_dataset, batch_size=4)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_pred_df = np.array([0]*pred_len*11).reshape(1,-1) #55주치를 예측하기위함\n",
    "    total_iter = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        #model.load_state_dict(torch.load(\"transformer_logreturn3.pth\", map_location=device))\n",
    "\n",
    "        for (inputs, dec_inputs, outputs) in total_loader:\n",
    "\n",
    "            #test_iter+=1\n",
    "\n",
    "            dec_inputs = dec_inputs.permute(1,0,2)\n",
    "            dec_inputs[optim_label_len:] = 0\n",
    "            dec_inputs = dec_inputs.permute(1,0,2)\n",
    "            src_mask = model.generate_square_subsequent_mask(inputs.shape[1]).to(device)\n",
    "            tgt_mask = model.generate_square_subsequent_mask(dec_inputs.shape[1]).to(device)\n",
    "\n",
    "            result = model(inputs.float().to(device), dec_inputs.float().to(device), src_mask, tgt_mask)\n",
    "\n",
    "            #if test_iter <= len(test_loader.dataset)-pred_len: #output의 실제값이 pred_len개 모두 존재하는 구간\n",
    "            #    test_loss += len(inputs)*criterion(result[label_len:].permute(1,0,2), outputs.float().to(device))/(len(test_loader.dataset)-pred_len)  \n",
    "            #print(result[label_len:].permute(1,0,2)[:,:,].cpu())\n",
    "\n",
    "            temp_inputs = copy.deepcopy(inputs)\n",
    "            temp_result = copy.deepcopy(result)\n",
    "            temp_dec_inputs = copy.deepcopy(dec_inputs)\n",
    "            concat_result = copy.deepcopy(result[optim_label_len:].permute(1,0,2)[:,:,0]).cpu()*(max_y-min_y)+min_y\n",
    "            for j in range(10): #55주후까지 예측\n",
    "                temp_inputs = torch.tensor(np.concatenate([temp_inputs[:,pred_len:,:],temp_result[optim_label_len:].permute(1,0,2)[:,:,].cpu()],axis=1))\n",
    "                if optim_label_len==0:\n",
    "                    temp_dec_inputs = torch.zeros(temp_inputs.shape[0],pred_len,temp_inputs.shape[2])\n",
    "                else:\n",
    "                    temp_dec_inputs = torch.tensor(np.concatenate([temp_inputs[:,-optim_label_len:,],torch.zeros(temp_inputs.shape[0],pred_len,temp_inputs.shape[2])],axis=1))\n",
    "                src_mask = model.generate_square_subsequent_mask(temp_inputs.shape[1]).to(device)\n",
    "                tgt_mask = model.generate_square_subsequent_mask(temp_dec_inputs.shape[1]).to(device)\n",
    "                temp_result = model(temp_inputs.float().to(device), temp_dec_inputs.float().to(device), src_mask, tgt_mask)\n",
    "                concat_result = np.concatenate([concat_result,temp_result[optim_label_len:].permute(1,0,2)[:,:,0].cpu()*(max_y-min_y)+min_y],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "            total_pred_df = np.concatenate([total_pred_df,concat_result])\n",
    "\n",
    "    for k in range(total.iloc[enc_len:,].shape[0]): #p번째 모델 total 기간 내 pred_date 1주씩 shift하며 순차적으로 전망치 저장 (향후 55주씩)\n",
    "        n_doc = copy.deepcopy(n_doc_def)\n",
    "        #print(test_y.iloc[k,]['Date'])\n",
    "        date_can = stre_date(pd.DataFrame([total_y.iloc[k,]['Date']], columns = ['Date']), \"WS\", end = total_y.iloc[k,]['Date']+relativedelta(weeks=54))\n",
    "\n",
    "        if k==0: #validation에서의 제일 마지막 값 참조\n",
    "            date_can['tf'+str(p+1)+'_'+'labellen'+str(optim_label_len)] = pd.Series(total_y.iloc[enc_len-1,1] * np.exp(np.cumsum(total_pred_df[k+1,])))\n",
    "        else:\n",
    "            date_can['tf'+str(p+1)+'_'+'labellen'+str(optim_label_len)] = pd.Series(total_y.iloc[k-1,]['data'] * np.exp(np.cumsum(total_pred_df[k+1,])))\n",
    "\n",
    "        if p > 0 :\n",
    "            sample = raw_coll.find_one({'dbcode': dbcode, 'pred_date':datetime.datetime(2011, 12, 19, 0, 0) + relativedelta(weeks=k+1),\"model_para\": {'freq': 'W', 'package': 'pytorch', 'dat_trans': 'log return', 'input_len':enc_len, 'output_len':pred_len},\"search_cols\": search_cols})\n",
    "            past_df = df_comp(sample['pred_val'])\n",
    "            n_doc[\"pred_val\"] = df_decomp(pd.merge(past_df,date_can,on='Date',how='left'))\n",
    "            n_doc[\"pred_date\"] = datetime.datetime(2011, 12, 19, 0, 0) + relativedelta(weeks=k+1)\n",
    "            raw_coll.update_one({'dbcode': dbcode, 'pred_date':datetime.datetime(2011, 12, 19, 0, 0) + relativedelta(weeks=k+1),\"model_para\": {'freq': 'W', 'package': 'pytorch', 'dat_trans': 'log return', 'input_len':enc_len, 'output_len':pred_len},\"search_cols\": search_cols}, {\"$set\":{\"pred_val\":n_doc[\"pred_val\"]}})\n",
    "        else:\n",
    "            n_doc[\"pred_val\"] = df_decomp(date_can)\n",
    "            n_doc[\"pred_date\"] = datetime.datetime(2011, 12, 19, 0, 0) + relativedelta(weeks=k+1)\n",
    "            raw_coll.insert_one(n_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef30b5",
   "metadata": {},
   "source": [
    "## 모델 validation 기간 내 평가 (score_df 만들것!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "853e150e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-12-26 00:00:00\n",
      "2012-01-02 00:00:00\n",
      "2012-01-09 00:00:00\n",
      "2012-01-16 00:00:00\n",
      "2012-01-23 00:00:00\n",
      "2012-01-30 00:00:00\n",
      "2012-02-06 00:00:00\n",
      "2012-02-13 00:00:00\n",
      "2012-02-20 00:00:00\n",
      "2012-02-27 00:00:00\n",
      "2012-03-05 00:00:00\n",
      "2012-03-12 00:00:00\n",
      "2012-03-19 00:00:00\n",
      "2012-03-26 00:00:00\n",
      "2012-04-02 00:00:00\n",
      "2012-04-09 00:00:00\n",
      "2012-04-16 00:00:00\n",
      "2012-04-23 00:00:00\n",
      "2012-04-30 00:00:00\n",
      "2012-05-07 00:00:00\n",
      "2012-05-14 00:00:00\n",
      "2012-05-21 00:00:00\n",
      "2012-05-28 00:00:00\n",
      "2012-06-04 00:00:00\n",
      "2012-06-11 00:00:00\n",
      "2012-06-18 00:00:00\n",
      "2012-06-25 00:00:00\n",
      "2012-07-02 00:00:00\n",
      "2012-07-09 00:00:00\n",
      "2012-07-16 00:00:00\n",
      "2012-07-23 00:00:00\n",
      "2012-07-30 00:00:00\n",
      "2012-08-06 00:00:00\n",
      "2012-08-13 00:00:00\n",
      "2012-08-20 00:00:00\n",
      "2012-08-27 00:00:00\n",
      "2012-09-03 00:00:00\n",
      "2012-09-10 00:00:00\n",
      "2012-09-17 00:00:00\n",
      "2012-09-24 00:00:00\n",
      "2012-10-01 00:00:00\n",
      "2012-10-08 00:00:00\n",
      "2012-10-15 00:00:00\n",
      "2012-10-22 00:00:00\n",
      "2012-10-29 00:00:00\n",
      "2012-11-05 00:00:00\n",
      "2012-11-12 00:00:00\n",
      "2012-11-19 00:00:00\n",
      "2012-11-26 00:00:00\n",
      "2012-12-03 00:00:00\n",
      "2012-12-10 00:00:00\n",
      "2012-12-17 00:00:00\n",
      "2012-12-24 00:00:00\n",
      "2012-12-31 00:00:00\n",
      "2013-01-07 00:00:00\n",
      "2013-01-14 00:00:00\n",
      "2013-01-21 00:00:00\n",
      "2013-01-28 00:00:00\n",
      "2013-02-04 00:00:00\n",
      "2013-02-11 00:00:00\n",
      "2013-02-18 00:00:00\n",
      "2013-02-25 00:00:00\n",
      "2013-03-04 00:00:00\n",
      "2013-03-11 00:00:00\n",
      "2013-03-18 00:00:00\n",
      "2013-03-25 00:00:00\n",
      "2013-04-01 00:00:00\n",
      "2013-04-08 00:00:00\n",
      "2013-04-15 00:00:00\n",
      "2013-04-22 00:00:00\n",
      "2013-04-29 00:00:00\n",
      "2013-05-06 00:00:00\n",
      "2013-05-13 00:00:00\n",
      "2013-05-20 00:00:00\n",
      "2013-05-27 00:00:00\n",
      "2013-06-03 00:00:00\n",
      "2013-06-10 00:00:00\n",
      "2013-06-17 00:00:00\n",
      "2013-06-24 00:00:00\n",
      "2013-07-01 00:00:00\n",
      "2013-07-08 00:00:00\n",
      "2013-07-15 00:00:00\n",
      "2013-07-22 00:00:00\n",
      "2013-07-29 00:00:00\n",
      "2013-08-05 00:00:00\n",
      "2013-08-12 00:00:00\n",
      "2013-08-19 00:00:00\n",
      "2013-08-26 00:00:00\n",
      "2013-09-02 00:00:00\n",
      "2013-09-09 00:00:00\n",
      "2013-09-16 00:00:00\n",
      "2013-09-23 00:00:00\n",
      "2013-09-30 00:00:00\n",
      "2013-10-07 00:00:00\n",
      "2013-10-14 00:00:00\n",
      "2013-10-21 00:00:00\n",
      "2013-10-28 00:00:00\n",
      "2013-11-04 00:00:00\n",
      "2013-11-11 00:00:00\n",
      "2013-11-18 00:00:00\n",
      "2013-11-25 00:00:00\n",
      "2013-12-02 00:00:00\n",
      "2013-12-09 00:00:00\n",
      "2013-12-16 00:00:00\n",
      "2013-12-23 00:00:00\n",
      "2013-12-30 00:00:00\n",
      "2014-01-06 00:00:00\n",
      "2014-01-13 00:00:00\n",
      "2014-01-20 00:00:00\n",
      "2014-01-27 00:00:00\n",
      "2014-02-03 00:00:00\n",
      "2014-02-10 00:00:00\n",
      "2014-02-17 00:00:00\n",
      "2014-02-24 00:00:00\n",
      "2014-03-03 00:00:00\n",
      "2014-03-10 00:00:00\n",
      "2014-03-17 00:00:00\n",
      "2014-03-24 00:00:00\n",
      "2014-03-31 00:00:00\n",
      "2014-04-07 00:00:00\n",
      "2014-04-14 00:00:00\n",
      "2014-04-21 00:00:00\n",
      "2014-04-28 00:00:00\n",
      "2014-05-05 00:00:00\n",
      "2014-05-12 00:00:00\n",
      "2014-05-19 00:00:00\n",
      "2014-05-26 00:00:00\n",
      "2014-06-02 00:00:00\n",
      "2014-06-09 00:00:00\n",
      "2014-06-16 00:00:00\n",
      "2014-06-23 00:00:00\n",
      "2014-06-30 00:00:00\n",
      "2014-07-07 00:00:00\n",
      "2014-07-14 00:00:00\n",
      "2014-07-21 00:00:00\n",
      "2014-07-28 00:00:00\n",
      "2014-08-04 00:00:00\n",
      "2014-08-11 00:00:00\n",
      "2014-08-18 00:00:00\n",
      "2014-08-25 00:00:00\n",
      "2014-09-01 00:00:00\n",
      "2014-09-08 00:00:00\n",
      "2014-09-15 00:00:00\n",
      "2014-09-22 00:00:00\n",
      "2014-09-29 00:00:00\n",
      "2014-10-06 00:00:00\n",
      "2014-10-13 00:00:00\n",
      "2014-10-20 00:00:00\n",
      "2014-10-27 00:00:00\n",
      "2014-11-03 00:00:00\n",
      "2014-11-10 00:00:00\n",
      "2014-11-17 00:00:00\n",
      "2014-11-24 00:00:00\n",
      "2014-12-01 00:00:00\n",
      "2014-12-08 00:00:00\n",
      "2014-12-15 00:00:00\n",
      "2014-12-22 00:00:00\n",
      "2014-12-29 00:00:00\n",
      "2015-01-05 00:00:00\n",
      "2015-01-12 00:00:00\n",
      "2015-01-19 00:00:00\n",
      "2015-01-26 00:00:00\n",
      "2015-02-02 00:00:00\n",
      "2015-02-09 00:00:00\n",
      "2015-02-16 00:00:00\n",
      "2015-02-23 00:00:00\n",
      "2015-03-02 00:00:00\n",
      "2015-03-09 00:00:00\n",
      "2015-03-16 00:00:00\n",
      "2015-03-23 00:00:00\n",
      "2015-03-30 00:00:00\n",
      "2015-04-06 00:00:00\n",
      "2015-04-13 00:00:00\n",
      "2015-04-20 00:00:00\n",
      "2015-04-27 00:00:00\n",
      "2015-05-04 00:00:00\n",
      "2015-05-11 00:00:00\n",
      "2015-05-18 00:00:00\n",
      "2015-05-25 00:00:00\n",
      "2015-06-01 00:00:00\n",
      "2015-06-08 00:00:00\n",
      "2015-06-15 00:00:00\n",
      "2015-06-22 00:00:00\n",
      "2015-06-29 00:00:00\n",
      "2015-07-06 00:00:00\n",
      "2015-07-13 00:00:00\n",
      "2015-07-20 00:00:00\n",
      "2015-07-27 00:00:00\n",
      "2015-08-03 00:00:00\n",
      "2015-08-10 00:00:00\n",
      "2015-08-17 00:00:00\n",
      "2015-08-24 00:00:00\n",
      "2015-08-31 00:00:00\n",
      "2015-09-07 00:00:00\n",
      "2015-09-14 00:00:00\n",
      "2015-09-21 00:00:00\n",
      "2015-09-28 00:00:00\n",
      "2015-10-05 00:00:00\n",
      "2015-10-12 00:00:00\n",
      "2015-10-19 00:00:00\n",
      "2015-10-26 00:00:00\n",
      "2015-11-02 00:00:00\n",
      "2015-11-09 00:00:00\n",
      "2015-11-16 00:00:00\n",
      "2015-11-23 00:00:00\n",
      "2015-11-30 00:00:00\n",
      "2015-12-07 00:00:00\n",
      "2015-12-14 00:00:00\n",
      "2015-12-21 00:00:00\n",
      "2015-12-28 00:00:00\n",
      "2016-01-04 00:00:00\n",
      "2016-01-11 00:00:00\n",
      "2016-01-18 00:00:00\n",
      "2016-01-25 00:00:00\n",
      "2016-02-01 00:00:00\n",
      "2016-02-08 00:00:00\n",
      "2016-02-15 00:00:00\n",
      "2016-02-22 00:00:00\n",
      "2016-02-29 00:00:00\n",
      "2016-03-07 00:00:00\n",
      "2016-03-14 00:00:00\n",
      "2016-03-21 00:00:00\n",
      "2016-03-28 00:00:00\n",
      "2016-04-04 00:00:00\n",
      "2016-04-11 00:00:00\n",
      "2016-04-18 00:00:00\n",
      "2016-04-25 00:00:00\n",
      "2016-05-02 00:00:00\n",
      "2016-05-09 00:00:00\n",
      "2016-05-16 00:00:00\n",
      "2016-05-23 00:00:00\n",
      "2016-05-30 00:00:00\n",
      "2016-06-06 00:00:00\n",
      "2016-06-13 00:00:00\n",
      "2016-06-20 00:00:00\n",
      "2016-06-27 00:00:00\n",
      "2016-07-04 00:00:00\n",
      "2016-07-11 00:00:00\n",
      "2016-07-18 00:00:00\n",
      "2016-07-25 00:00:00\n",
      "2016-08-01 00:00:00\n",
      "2016-08-08 00:00:00\n",
      "2016-08-15 00:00:00\n",
      "2016-08-22 00:00:00\n",
      "2016-08-29 00:00:00\n",
      "2016-09-05 00:00:00\n",
      "2016-09-12 00:00:00\n",
      "2016-09-19 00:00:00\n",
      "2016-09-26 00:00:00\n",
      "2016-10-03 00:00:00\n",
      "2016-10-10 00:00:00\n",
      "2016-10-17 00:00:00\n",
      "2016-10-24 00:00:00\n",
      "2016-10-31 00:00:00\n",
      "2016-11-07 00:00:00\n",
      "2016-11-14 00:00:00\n",
      "2016-11-21 00:00:00\n",
      "2016-11-28 00:00:00\n",
      "2016-12-05 00:00:00\n",
      "2016-12-12 00:00:00\n",
      "2016-12-19 00:00:00\n",
      "2016-12-26 00:00:00\n",
      "2017-01-02 00:00:00\n",
      "2017-01-09 00:00:00\n",
      "2017-01-16 00:00:00\n",
      "2017-01-23 00:00:00\n",
      "2017-01-30 00:00:00\n",
      "2017-02-06 00:00:00\n",
      "2017-02-13 00:00:00\n",
      "2017-02-20 00:00:00\n",
      "2017-02-27 00:00:00\n",
      "2017-03-06 00:00:00\n",
      "2017-03-13 00:00:00\n",
      "2017-03-20 00:00:00\n",
      "2017-03-27 00:00:00\n",
      "2017-04-03 00:00:00\n",
      "2017-04-10 00:00:00\n",
      "2017-04-17 00:00:00\n",
      "2017-04-24 00:00:00\n",
      "2017-05-01 00:00:00\n",
      "2017-05-08 00:00:00\n",
      "2017-05-15 00:00:00\n",
      "2017-05-22 00:00:00\n",
      "2017-05-29 00:00:00\n",
      "2017-06-05 00:00:00\n",
      "2017-06-12 00:00:00\n",
      "2017-06-19 00:00:00\n",
      "2017-06-26 00:00:00\n",
      "2017-07-03 00:00:00\n",
      "2017-07-10 00:00:00\n",
      "2017-07-17 00:00:00\n",
      "2017-07-24 00:00:00\n",
      "2017-07-31 00:00:00\n",
      "2017-08-07 00:00:00\n",
      "2017-08-14 00:00:00\n",
      "2017-08-21 00:00:00\n",
      "2017-08-28 00:00:00\n",
      "2017-09-04 00:00:00\n",
      "2017-09-11 00:00:00\n",
      "2017-09-18 00:00:00\n",
      "2017-09-25 00:00:00\n",
      "2017-10-02 00:00:00\n",
      "2017-10-09 00:00:00\n",
      "2017-10-16 00:00:00\n",
      "2017-10-23 00:00:00\n",
      "2017-10-30 00:00:00\n",
      "2017-11-06 00:00:00\n",
      "2017-11-13 00:00:00\n",
      "2017-11-20 00:00:00\n",
      "2017-11-27 00:00:00\n",
      "2017-12-04 00:00:00\n",
      "2017-12-11 00:00:00\n",
      "2017-12-18 00:00:00\n",
      "2017-12-25 00:00:00\n",
      "2018-01-01 00:00:00\n",
      "2018-01-08 00:00:00\n",
      "2018-01-15 00:00:00\n",
      "2018-01-22 00:00:00\n",
      "2018-01-29 00:00:00\n",
      "2018-02-05 00:00:00\n",
      "2018-02-12 00:00:00\n",
      "2018-02-19 00:00:00\n",
      "2018-02-26 00:00:00\n",
      "2018-03-05 00:00:00\n",
      "2018-03-12 00:00:00\n",
      "2018-03-19 00:00:00\n",
      "2018-03-26 00:00:00\n",
      "2018-04-02 00:00:00\n",
      "2018-04-09 00:00:00\n",
      "2018-04-16 00:00:00\n",
      "2018-04-23 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "2018-05-07 00:00:00\n",
      "2018-05-14 00:00:00\n",
      "2018-05-21 00:00:00\n",
      "2018-05-28 00:00:00\n",
      "2018-06-04 00:00:00\n",
      "2018-06-11 00:00:00\n",
      "2018-06-18 00:00:00\n",
      "2018-06-25 00:00:00\n",
      "2018-07-02 00:00:00\n",
      "2018-07-09 00:00:00\n",
      "2018-07-16 00:00:00\n",
      "2018-07-23 00:00:00\n",
      "2018-07-30 00:00:00\n",
      "2018-08-06 00:00:00\n",
      "2018-08-13 00:00:00\n",
      "2018-08-20 00:00:00\n",
      "2018-08-27 00:00:00\n",
      "2018-09-03 00:00:00\n",
      "2018-09-10 00:00:00\n",
      "2018-09-17 00:00:00\n",
      "2018-09-24 00:00:00\n",
      "2018-10-01 00:00:00\n",
      "2018-10-08 00:00:00\n",
      "2018-10-15 00:00:00\n",
      "2018-10-22 00:00:00\n",
      "2018-10-29 00:00:00\n",
      "2018-11-05 00:00:00\n",
      "2018-11-12 00:00:00\n",
      "2018-11-19 00:00:00\n",
      "2018-11-26 00:00:00\n",
      "2018-12-03 00:00:00\n",
      "2018-12-10 00:00:00\n",
      "2018-12-17 00:00:00\n",
      "2018-12-24 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-01-07 00:00:00\n",
      "2019-01-14 00:00:00\n",
      "2019-01-21 00:00:00\n",
      "2019-01-28 00:00:00\n",
      "2019-02-04 00:00:00\n",
      "2019-02-11 00:00:00\n",
      "2019-02-18 00:00:00\n",
      "2019-02-25 00:00:00\n",
      "2019-03-04 00:00:00\n",
      "2019-03-11 00:00:00\n",
      "2019-03-18 00:00:00\n",
      "2019-03-25 00:00:00\n",
      "2019-04-01 00:00:00\n",
      "2019-04-08 00:00:00\n",
      "2019-04-15 00:00:00\n",
      "2019-04-22 00:00:00\n",
      "2019-04-29 00:00:00\n",
      "2019-05-06 00:00:00\n",
      "2019-05-13 00:00:00\n",
      "2019-05-20 00:00:00\n",
      "2019-05-27 00:00:00\n",
      "2019-06-03 00:00:00\n",
      "2019-06-10 00:00:00\n",
      "2019-06-17 00:00:00\n",
      "2019-06-24 00:00:00\n",
      "2019-07-01 00:00:00\n",
      "2019-07-08 00:00:00\n",
      "2019-07-15 00:00:00\n",
      "2019-07-22 00:00:00\n",
      "2019-07-29 00:00:00\n",
      "2019-08-05 00:00:00\n",
      "2019-08-12 00:00:00\n",
      "2019-08-19 00:00:00\n",
      "2019-08-26 00:00:00\n",
      "2019-09-02 00:00:00\n",
      "2019-09-09 00:00:00\n",
      "2019-09-16 00:00:00\n",
      "2019-09-23 00:00:00\n",
      "2019-09-30 00:00:00\n",
      "2019-10-07 00:00:00\n",
      "2019-10-14 00:00:00\n",
      "2019-10-21 00:00:00\n",
      "2019-10-28 00:00:00\n",
      "2019-11-04 00:00:00\n",
      "2019-11-11 00:00:00\n",
      "2019-11-18 00:00:00\n",
      "2019-11-25 00:00:00\n",
      "2019-12-02 00:00:00\n",
      "2019-12-09 00:00:00\n",
      "2019-12-16 00:00:00\n",
      "2019-12-23 00:00:00\n",
      "2019-12-30 00:00:00\n",
      "2020-01-06 00:00:00\n",
      "2020-01-13 00:00:00\n",
      "2020-01-20 00:00:00\n",
      "2020-01-27 00:00:00\n",
      "2020-02-03 00:00:00\n",
      "2020-02-10 00:00:00\n",
      "2020-02-17 00:00:00\n",
      "2020-02-24 00:00:00\n",
      "2020-03-02 00:00:00\n",
      "2020-03-09 00:00:00\n",
      "2020-03-16 00:00:00\n",
      "2020-03-23 00:00:00\n",
      "2020-03-30 00:00:00\n",
      "2020-04-06 00:00:00\n",
      "2020-04-13 00:00:00\n",
      "2020-04-20 00:00:00\n",
      "2020-04-27 00:00:00\n",
      "2020-05-04 00:00:00\n",
      "2020-05-11 00:00:00\n",
      "2020-05-18 00:00:00\n",
      "2020-05-25 00:00:00\n",
      "2020-06-01 00:00:00\n",
      "2020-06-08 00:00:00\n",
      "2020-06-15 00:00:00\n",
      "2020-06-22 00:00:00\n",
      "2020-06-29 00:00:00\n",
      "2020-07-06 00:00:00\n",
      "2020-07-13 00:00:00\n",
      "2020-07-20 00:00:00\n",
      "2020-07-27 00:00:00\n",
      "2020-08-03 00:00:00\n",
      "2020-08-10 00:00:00\n",
      "2020-08-17 00:00:00\n",
      "2020-08-24 00:00:00\n",
      "2020-08-31 00:00:00\n",
      "2020-09-07 00:00:00\n",
      "2020-09-14 00:00:00\n",
      "2020-09-21 00:00:00\n",
      "2020-09-28 00:00:00\n",
      "2020-10-05 00:00:00\n",
      "2020-10-12 00:00:00\n",
      "2020-10-19 00:00:00\n",
      "2020-10-26 00:00:00\n",
      "2020-11-02 00:00:00\n",
      "2020-11-09 00:00:00\n",
      "2020-11-16 00:00:00\n",
      "2020-11-23 00:00:00\n",
      "2020-11-30 00:00:00\n",
      "2020-12-07 00:00:00\n",
      "2020-12-14 00:00:00\n",
      "2020-12-21 00:00:00\n",
      "2020-12-28 00:00:00\n",
      "2021-01-04 00:00:00\n",
      "2021-01-11 00:00:00\n",
      "2021-01-18 00:00:00\n",
      "2021-01-25 00:00:00\n",
      "2021-02-01 00:00:00\n",
      "2021-02-08 00:00:00\n",
      "2021-02-15 00:00:00\n",
      "2021-02-22 00:00:00\n",
      "2021-03-01 00:00:00\n",
      "2021-03-08 00:00:00\n",
      "2021-03-15 00:00:00\n",
      "2021-03-22 00:00:00\n",
      "2021-03-29 00:00:00\n",
      "2021-04-05 00:00:00\n",
      "2021-04-12 00:00:00\n",
      "2021-04-19 00:00:00\n",
      "2021-04-26 00:00:00\n",
      "2021-05-03 00:00:00\n",
      "2021-05-10 00:00:00\n",
      "2021-05-17 00:00:00\n",
      "2021-05-24 00:00:00\n",
      "2021-05-31 00:00:00\n",
      "2021-06-07 00:00:00\n",
      "2021-06-14 00:00:00\n",
      "2021-06-21 00:00:00\n",
      "2021-06-28 00:00:00\n",
      "2021-07-05 00:00:00\n",
      "2021-07-12 00:00:00\n",
      "2021-07-19 00:00:00\n",
      "2021-07-26 00:00:00\n",
      "2021-08-02 00:00:00\n",
      "2021-08-09 00:00:00\n",
      "2021-08-16 00:00:00\n",
      "2021-08-23 00:00:00\n",
      "2021-08-30 00:00:00\n",
      "2021-09-06 00:00:00\n",
      "2021-09-13 00:00:00\n",
      "2021-09-20 00:00:00\n",
      "2021-09-27 00:00:00\n",
      "2021-10-04 00:00:00\n",
      "2021-10-11 00:00:00\n",
      "2021-10-18 00:00:00\n",
      "2021-10-25 00:00:00\n",
      "2021-11-01 00:00:00\n",
      "2021-11-08 00:00:00\n",
      "2021-11-15 00:00:00\n",
      "2021-11-22 00:00:00\n",
      "2021-11-29 00:00:00\n",
      "2021-12-06 00:00:00\n",
      "2021-12-13 00:00:00\n",
      "2021-12-20 00:00:00\n",
      "2021-12-27 00:00:00\n",
      "2022-01-03 00:00:00\n",
      "2022-01-10 00:00:00\n",
      "2022-01-17 00:00:00\n",
      "2022-01-24 00:00:00\n",
      "2022-01-31 00:00:00\n",
      "2022-02-07 00:00:00\n",
      "2022-02-14 00:00:00\n",
      "2022-02-21 00:00:00\n",
      "2022-02-28 00:00:00\n",
      "2022-03-07 00:00:00\n",
      "2022-03-14 00:00:00\n",
      "2022-03-21 00:00:00\n",
      "2022-03-28 00:00:00\n",
      "2022-04-04 00:00:00\n",
      "2022-04-11 00:00:00\n",
      "2022-04-18 00:00:00\n",
      "2022-04-25 00:00:00\n",
      "2022-05-02 00:00:00\n",
      "2022-05-09 00:00:00\n",
      "2022-05-16 00:00:00\n",
      "2022-05-23 00:00:00\n",
      "2022-05-30 00:00:00\n",
      "2022-06-06 00:00:00\n",
      "2022-06-13 00:00:00\n",
      "2022-06-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "pred_date_li = []\n",
    "for q in raw_coll.find({'dbcode':dbcode, \"model_para\":{'freq': 'W', 'package': 'pytorch', 'dat_trans': 'log return', 'input_len':enc_len, 'output_len':pred_len},\n",
    "                      \"search_cols\": search_cols}):\n",
    "    print(q['pred_date'])\n",
    "    pred_date_li += [q['pred_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d4d1c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2020-06-15 00:00:00'),\n",
       " Timestamp('2020-07-20 00:00:00'),\n",
       " Timestamp('2020-08-17 00:00:00'),\n",
       " Timestamp('2020-09-14 00:00:00'),\n",
       " Timestamp('2020-10-19 00:00:00'),\n",
       " Timestamp('2020-11-16 00:00:00'),\n",
       " Timestamp('2020-12-14 00:00:00'),\n",
       " Timestamp('2021-01-18 00:00:00'),\n",
       " Timestamp('2021-02-15 00:00:00'),\n",
       " Timestamp('2021-03-15 00:00:00'),\n",
       " Timestamp('2021-04-19 00:00:00'),\n",
       " Timestamp('2021-05-17 00:00:00'),\n",
       " Timestamp('2021-06-14 00:00:00'),\n",
       " Timestamp('2021-07-19 00:00:00'),\n",
       " Timestamp('2021-08-16 00:00:00'),\n",
       " Timestamp('2021-09-20 00:00:00'),\n",
       " Timestamp('2021-10-18 00:00:00'),\n",
       " Timestamp('2021-11-15 00:00:00'),\n",
       " Timestamp('2021-12-20 00:00:00'),\n",
       " Timestamp('2022-01-17 00:00:00'),\n",
       " Timestamp('2022-02-14 00:00:00'),\n",
       " Timestamp('2022-03-14 00:00:00'),\n",
       " Timestamp('2022-04-18 00:00:00'),\n",
       " Timestamp('2022-05-16 00:00:00'),\n",
       " Timestamp('2022-06-20 00:00:00')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_li = list(pd.Series(pred_date_li)[pd.Series(pred_date_li).map(lambda x: x>=datetime.datetime(2020, 6, 14, 0, 0) and 14<=x.day<=20)]) #추후 변경 필요할지도.. 21일 포함 X\n",
    "valid_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5336db17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2020-06-15 00:00:00'),\n",
       " Timestamp('2020-07-20 00:00:00'),\n",
       " Timestamp('2020-08-17 00:00:00'),\n",
       " Timestamp('2020-09-14 00:00:00'),\n",
       " Timestamp('2020-10-19 00:00:00'),\n",
       " Timestamp('2020-11-16 00:00:00'),\n",
       " Timestamp('2020-12-14 00:00:00'),\n",
       " Timestamp('2021-01-18 00:00:00'),\n",
       " Timestamp('2021-02-15 00:00:00'),\n",
       " Timestamp('2021-03-15 00:00:00'),\n",
       " Timestamp('2021-04-19 00:00:00'),\n",
       " Timestamp('2021-05-17 00:00:00')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_li[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34de2880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id',\n",
       " 'model_type',\n",
       " 'model_writer',\n",
       " 'ensemble',\n",
       " 'reg_date',\n",
       " 'model_para',\n",
       " 'item_name',\n",
       " 'item_spec',\n",
       " 'dbcode',\n",
       " 'search_cols',\n",
       " 'pred_val',\n",
       " 'pred_date']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "114536bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf1_labellen8',\n",
       " 'tf2_labellen4',\n",
       " 'tf3_labellen12',\n",
       " 'tf4_labellen4',\n",
       " 'tf5_labellen4',\n",
       " 'tf6_labellen8',\n",
       " 'tf7_labellen8',\n",
       " 'tf8_labellen12',\n",
       " 'tf9_labellen4',\n",
       " 'tf10_labellen0']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_comp(q['pred_val']).columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3d3f2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      5.280814\n",
      "1      9.367037\n",
      "2     10.042212\n",
      "3     10.587784\n",
      "4     10.852314\n",
      "5     10.607072\n",
      "6     10.576156\n",
      "7     14.220188\n",
      "8     17.667956\n",
      "9     20.601425\n",
      "10    24.738784\n",
      "11    31.377717\n",
      "dtype: float64\n",
      "0      4.507479\n",
      "1      8.110966\n",
      "2     11.121550\n",
      "3     12.722048\n",
      "4     12.302789\n",
      "5     11.873417\n",
      "6     13.229267\n",
      "7     14.945060\n",
      "8     16.041722\n",
      "9     15.808911\n",
      "10    17.675125\n",
      "11    19.211500\n",
      "dtype: float64\n",
      "0      4.960433\n",
      "1      9.152879\n",
      "2     13.241038\n",
      "3     15.595220\n",
      "4     16.192387\n",
      "5     16.255304\n",
      "6     19.390875\n",
      "7     23.076655\n",
      "8     27.422156\n",
      "9     30.537062\n",
      "10    34.038514\n",
      "11    37.607511\n",
      "dtype: float64\n",
      "0      4.080998\n",
      "1      6.860480\n",
      "2      8.065282\n",
      "3      8.648728\n",
      "4     11.193543\n",
      "5     13.338203\n",
      "6     15.640563\n",
      "7     17.686281\n",
      "8     20.169860\n",
      "9     23.827180\n",
      "10    25.119907\n",
      "11    24.560626\n",
      "dtype: float64\n",
      "0       7.017394\n",
      "1      11.894972\n",
      "2      17.415228\n",
      "3      23.108138\n",
      "4      30.568629\n",
      "5      37.559882\n",
      "6      45.832154\n",
      "7      57.398994\n",
      "8      72.169259\n",
      "9      85.449519\n",
      "10     98.275389\n",
      "11    113.199204\n",
      "dtype: float64\n",
      "0       7.055279\n",
      "1      13.129918\n",
      "2      21.317472\n",
      "3      27.386961\n",
      "4      33.020149\n",
      "5      39.828104\n",
      "6      49.812677\n",
      "7      60.162372\n",
      "8      71.584590\n",
      "9      81.720188\n",
      "10     92.858277\n",
      "11    104.628571\n",
      "dtype: float64\n",
      "0      5.232359\n",
      "1     10.581609\n",
      "2     16.861987\n",
      "3     20.588662\n",
      "4     22.353990\n",
      "5     24.733221\n",
      "6     29.865149\n",
      "7     33.584569\n",
      "8     36.781821\n",
      "9     41.370127\n",
      "10    46.871605\n",
      "11    49.220628\n",
      "dtype: float64\n",
      "0      5.146873\n",
      "1      8.917326\n",
      "2     10.829940\n",
      "3     12.851343\n",
      "4     16.294996\n",
      "5     19.799488\n",
      "6     21.677582\n",
      "7     23.764514\n",
      "8     25.712804\n",
      "9     28.351640\n",
      "10    30.706683\n",
      "11    32.990651\n",
      "dtype: float64\n",
      "0      4.271581\n",
      "1      7.810607\n",
      "2      9.403317\n",
      "3      9.786031\n",
      "4     10.722129\n",
      "5     11.565894\n",
      "6     12.019384\n",
      "7     12.642464\n",
      "8     13.667158\n",
      "9     14.872514\n",
      "10    13.706468\n",
      "11    13.688964\n",
      "dtype: float64\n",
      "0      5.048477\n",
      "1      8.640298\n",
      "2     10.552084\n",
      "3     12.336683\n",
      "4     15.334870\n",
      "5     18.642700\n",
      "6     20.358112\n",
      "7     22.292694\n",
      "8     24.093849\n",
      "9     26.613438\n",
      "10    28.855622\n",
      "11    31.035972\n",
      "dtype: float64\n",
      "0      4.263309\n",
      "1      7.373552\n",
      "2      9.356262\n",
      "3     10.611046\n",
      "4     10.136547\n",
      "5      9.521386\n",
      "6     10.864277\n",
      "7     13.166382\n",
      "8     16.805103\n",
      "9     18.148365\n",
      "10    20.475827\n",
      "11    23.746834\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "valid_score = pd.DataFrame()\n",
    "\n",
    "for j in range(1,12,1):\n",
    "    mape_record = pd.Series([0]*12)\n",
    "    for k in valid_li[:12]:\n",
    "        sample2 = raw_coll.find_one({'dbcode':dbcode, \"model_para\":{'freq': 'W', 'package': 'pytorch', 'dat_trans': 'log return', 'input_len':enc_len, 'output_len':pred_len},\n",
    "                      \"search_cols\": search_cols, \"pred_date\":k})\n",
    "        temp_record = dat_ave(df_comp(sample2['pred_val']))[1:13]\n",
    "        temp_record['average'] = temp_record.iloc[:,range(1,11,1)].apply(np.average,axis=1)\n",
    "        iron = pr_q_slim(dbcode)\n",
    "        iron = dat_ave(iron)\n",
    "        temp_record2 = pd.merge(temp_record,iron,how='left',on='Date')\n",
    "        mape_record += abs((temp_record2.iloc[:,j] - temp_record2.iloc[:,-1]) / temp_record2.iloc[:,-1]) * 100 #mape of 1M ~ 12M\n",
    "    print(mape_record/12)\n",
    "    valid_score = pd.concat([valid_score,mape_record/12],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e097f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_score.columns = list(df_comp(q['pred_val']).columns[1:]) + ['average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6654f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_score.index = [str(k)+\"M spot\" for k in range(1,13,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68c0c1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf1_labellen8</th>\n",
       "      <th>tf2_labellen4</th>\n",
       "      <th>tf3_labellen12</th>\n",
       "      <th>tf4_labellen4</th>\n",
       "      <th>tf5_labellen4</th>\n",
       "      <th>tf6_labellen8</th>\n",
       "      <th>tf7_labellen8</th>\n",
       "      <th>tf8_labellen12</th>\n",
       "      <th>tf9_labellen4</th>\n",
       "      <th>tf10_labellen0</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1M spot</th>\n",
       "      <td>5.280814</td>\n",
       "      <td>4.507479</td>\n",
       "      <td>4.960433</td>\n",
       "      <td>4.080998</td>\n",
       "      <td>7.017394</td>\n",
       "      <td>7.055279</td>\n",
       "      <td>5.232359</td>\n",
       "      <td>5.146873</td>\n",
       "      <td>4.271581</td>\n",
       "      <td>5.048477</td>\n",
       "      <td>4.263309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2M spot</th>\n",
       "      <td>9.367037</td>\n",
       "      <td>8.110966</td>\n",
       "      <td>9.152879</td>\n",
       "      <td>6.860480</td>\n",
       "      <td>11.894972</td>\n",
       "      <td>13.129918</td>\n",
       "      <td>10.581609</td>\n",
       "      <td>8.917326</td>\n",
       "      <td>7.810607</td>\n",
       "      <td>8.640298</td>\n",
       "      <td>7.373552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3M spot</th>\n",
       "      <td>10.042212</td>\n",
       "      <td>11.121550</td>\n",
       "      <td>13.241038</td>\n",
       "      <td>8.065282</td>\n",
       "      <td>17.415228</td>\n",
       "      <td>21.317472</td>\n",
       "      <td>16.861987</td>\n",
       "      <td>10.829940</td>\n",
       "      <td>9.403317</td>\n",
       "      <td>10.552084</td>\n",
       "      <td>9.356262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4M spot</th>\n",
       "      <td>10.587784</td>\n",
       "      <td>12.722048</td>\n",
       "      <td>15.595220</td>\n",
       "      <td>8.648728</td>\n",
       "      <td>23.108138</td>\n",
       "      <td>27.386961</td>\n",
       "      <td>20.588662</td>\n",
       "      <td>12.851343</td>\n",
       "      <td>9.786031</td>\n",
       "      <td>12.336683</td>\n",
       "      <td>10.611046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5M spot</th>\n",
       "      <td>10.852314</td>\n",
       "      <td>12.302789</td>\n",
       "      <td>16.192387</td>\n",
       "      <td>11.193543</td>\n",
       "      <td>30.568629</td>\n",
       "      <td>33.020149</td>\n",
       "      <td>22.353990</td>\n",
       "      <td>16.294996</td>\n",
       "      <td>10.722129</td>\n",
       "      <td>15.334870</td>\n",
       "      <td>10.136547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6M spot</th>\n",
       "      <td>10.607072</td>\n",
       "      <td>11.873417</td>\n",
       "      <td>16.255304</td>\n",
       "      <td>13.338203</td>\n",
       "      <td>37.559882</td>\n",
       "      <td>39.828104</td>\n",
       "      <td>24.733221</td>\n",
       "      <td>19.799488</td>\n",
       "      <td>11.565894</td>\n",
       "      <td>18.642700</td>\n",
       "      <td>9.521386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7M spot</th>\n",
       "      <td>10.576156</td>\n",
       "      <td>13.229267</td>\n",
       "      <td>19.390875</td>\n",
       "      <td>15.640563</td>\n",
       "      <td>45.832154</td>\n",
       "      <td>49.812677</td>\n",
       "      <td>29.865149</td>\n",
       "      <td>21.677582</td>\n",
       "      <td>12.019384</td>\n",
       "      <td>20.358112</td>\n",
       "      <td>10.864277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8M spot</th>\n",
       "      <td>14.220188</td>\n",
       "      <td>14.945060</td>\n",
       "      <td>23.076655</td>\n",
       "      <td>17.686281</td>\n",
       "      <td>57.398994</td>\n",
       "      <td>60.162372</td>\n",
       "      <td>33.584569</td>\n",
       "      <td>23.764514</td>\n",
       "      <td>12.642464</td>\n",
       "      <td>22.292694</td>\n",
       "      <td>13.166382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9M spot</th>\n",
       "      <td>17.667956</td>\n",
       "      <td>16.041722</td>\n",
       "      <td>27.422156</td>\n",
       "      <td>20.169860</td>\n",
       "      <td>72.169259</td>\n",
       "      <td>71.584590</td>\n",
       "      <td>36.781821</td>\n",
       "      <td>25.712804</td>\n",
       "      <td>13.667158</td>\n",
       "      <td>24.093849</td>\n",
       "      <td>16.805103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10M spot</th>\n",
       "      <td>20.601425</td>\n",
       "      <td>15.808911</td>\n",
       "      <td>30.537062</td>\n",
       "      <td>23.827180</td>\n",
       "      <td>85.449519</td>\n",
       "      <td>81.720188</td>\n",
       "      <td>41.370127</td>\n",
       "      <td>28.351640</td>\n",
       "      <td>14.872514</td>\n",
       "      <td>26.613438</td>\n",
       "      <td>18.148365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11M spot</th>\n",
       "      <td>24.738784</td>\n",
       "      <td>17.675125</td>\n",
       "      <td>34.038514</td>\n",
       "      <td>25.119907</td>\n",
       "      <td>98.275389</td>\n",
       "      <td>92.858277</td>\n",
       "      <td>46.871605</td>\n",
       "      <td>30.706683</td>\n",
       "      <td>13.706468</td>\n",
       "      <td>28.855622</td>\n",
       "      <td>20.475827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12M spot</th>\n",
       "      <td>31.377717</td>\n",
       "      <td>19.211500</td>\n",
       "      <td>37.607511</td>\n",
       "      <td>24.560626</td>\n",
       "      <td>113.199204</td>\n",
       "      <td>104.628571</td>\n",
       "      <td>49.220628</td>\n",
       "      <td>32.990651</td>\n",
       "      <td>13.688964</td>\n",
       "      <td>31.035972</td>\n",
       "      <td>23.746834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tf1_labellen8  tf2_labellen4  tf3_labellen12  tf4_labellen4  \\\n",
       "1M spot        5.280814       4.507479        4.960433       4.080998   \n",
       "2M spot        9.367037       8.110966        9.152879       6.860480   \n",
       "3M spot       10.042212      11.121550       13.241038       8.065282   \n",
       "4M spot       10.587784      12.722048       15.595220       8.648728   \n",
       "5M spot       10.852314      12.302789       16.192387      11.193543   \n",
       "6M spot       10.607072      11.873417       16.255304      13.338203   \n",
       "7M spot       10.576156      13.229267       19.390875      15.640563   \n",
       "8M spot       14.220188      14.945060       23.076655      17.686281   \n",
       "9M spot       17.667956      16.041722       27.422156      20.169860   \n",
       "10M spot      20.601425      15.808911       30.537062      23.827180   \n",
       "11M spot      24.738784      17.675125       34.038514      25.119907   \n",
       "12M spot      31.377717      19.211500       37.607511      24.560626   \n",
       "\n",
       "          tf5_labellen4  tf6_labellen8  tf7_labellen8  tf8_labellen12  \\\n",
       "1M spot        7.017394       7.055279       5.232359        5.146873   \n",
       "2M spot       11.894972      13.129918      10.581609        8.917326   \n",
       "3M spot       17.415228      21.317472      16.861987       10.829940   \n",
       "4M spot       23.108138      27.386961      20.588662       12.851343   \n",
       "5M spot       30.568629      33.020149      22.353990       16.294996   \n",
       "6M spot       37.559882      39.828104      24.733221       19.799488   \n",
       "7M spot       45.832154      49.812677      29.865149       21.677582   \n",
       "8M spot       57.398994      60.162372      33.584569       23.764514   \n",
       "9M spot       72.169259      71.584590      36.781821       25.712804   \n",
       "10M spot      85.449519      81.720188      41.370127       28.351640   \n",
       "11M spot      98.275389      92.858277      46.871605       30.706683   \n",
       "12M spot     113.199204     104.628571      49.220628       32.990651   \n",
       "\n",
       "          tf9_labellen4  tf10_labellen0    average  \n",
       "1M spot        4.271581        5.048477   4.263309  \n",
       "2M spot        7.810607        8.640298   7.373552  \n",
       "3M spot        9.403317       10.552084   9.356262  \n",
       "4M spot        9.786031       12.336683  10.611046  \n",
       "5M spot       10.722129       15.334870  10.136547  \n",
       "6M spot       11.565894       18.642700   9.521386  \n",
       "7M spot       12.019384       20.358112  10.864277  \n",
       "8M spot       12.642464       22.292694  13.166382  \n",
       "9M spot       13.667158       24.093849  16.805103  \n",
       "10M spot      14.872514       26.613438  18.148365  \n",
       "11M spot      13.706468       28.855622  20.475827  \n",
       "12M spot      13.688964       31.035972  23.746834  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3317e",
   "metadata": {},
   "source": [
    "## 모델 test 기간 내 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1bffbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-12-26 00:00:00\n",
      "2012-01-02 00:00:00\n",
      "2012-01-09 00:00:00\n",
      "2012-01-16 00:00:00\n",
      "2012-01-23 00:00:00\n",
      "2012-01-30 00:00:00\n",
      "2012-02-06 00:00:00\n",
      "2012-02-13 00:00:00\n",
      "2012-02-20 00:00:00\n",
      "2012-02-27 00:00:00\n",
      "2012-03-05 00:00:00\n",
      "2012-03-12 00:00:00\n",
      "2012-03-19 00:00:00\n",
      "2012-03-26 00:00:00\n",
      "2012-04-02 00:00:00\n",
      "2012-04-09 00:00:00\n",
      "2012-04-16 00:00:00\n",
      "2012-04-23 00:00:00\n",
      "2012-04-30 00:00:00\n",
      "2012-05-07 00:00:00\n",
      "2012-05-14 00:00:00\n",
      "2012-05-21 00:00:00\n",
      "2012-05-28 00:00:00\n",
      "2012-06-04 00:00:00\n",
      "2012-06-11 00:00:00\n",
      "2012-06-18 00:00:00\n",
      "2012-06-25 00:00:00\n",
      "2012-07-02 00:00:00\n",
      "2012-07-09 00:00:00\n",
      "2012-07-16 00:00:00\n",
      "2012-07-23 00:00:00\n",
      "2012-07-30 00:00:00\n",
      "2012-08-06 00:00:00\n",
      "2012-08-13 00:00:00\n",
      "2012-08-20 00:00:00\n",
      "2012-08-27 00:00:00\n",
      "2012-09-03 00:00:00\n",
      "2012-09-10 00:00:00\n",
      "2012-09-17 00:00:00\n",
      "2012-09-24 00:00:00\n",
      "2012-10-01 00:00:00\n",
      "2012-10-08 00:00:00\n",
      "2012-10-15 00:00:00\n",
      "2012-10-22 00:00:00\n",
      "2012-10-29 00:00:00\n",
      "2012-11-05 00:00:00\n",
      "2012-11-12 00:00:00\n",
      "2012-11-19 00:00:00\n",
      "2012-11-26 00:00:00\n",
      "2012-12-03 00:00:00\n",
      "2012-12-10 00:00:00\n",
      "2012-12-17 00:00:00\n",
      "2012-12-24 00:00:00\n",
      "2012-12-31 00:00:00\n",
      "2013-01-07 00:00:00\n",
      "2013-01-14 00:00:00\n",
      "2013-01-21 00:00:00\n",
      "2013-01-28 00:00:00\n",
      "2013-02-04 00:00:00\n",
      "2013-02-11 00:00:00\n",
      "2013-02-18 00:00:00\n",
      "2013-02-25 00:00:00\n",
      "2013-03-04 00:00:00\n",
      "2013-03-11 00:00:00\n",
      "2013-03-18 00:00:00\n",
      "2013-03-25 00:00:00\n",
      "2013-04-01 00:00:00\n",
      "2013-04-08 00:00:00\n",
      "2013-04-15 00:00:00\n",
      "2013-04-22 00:00:00\n",
      "2013-04-29 00:00:00\n",
      "2013-05-06 00:00:00\n",
      "2013-05-13 00:00:00\n",
      "2013-05-20 00:00:00\n",
      "2013-05-27 00:00:00\n",
      "2013-06-03 00:00:00\n",
      "2013-06-10 00:00:00\n",
      "2013-06-17 00:00:00\n",
      "2013-06-24 00:00:00\n",
      "2013-07-01 00:00:00\n",
      "2013-07-08 00:00:00\n",
      "2013-07-15 00:00:00\n",
      "2013-07-22 00:00:00\n",
      "2013-07-29 00:00:00\n",
      "2013-08-05 00:00:00\n",
      "2013-08-12 00:00:00\n",
      "2013-08-19 00:00:00\n",
      "2013-08-26 00:00:00\n",
      "2013-09-02 00:00:00\n",
      "2013-09-09 00:00:00\n",
      "2013-09-16 00:00:00\n",
      "2013-09-23 00:00:00\n",
      "2013-09-30 00:00:00\n",
      "2013-10-07 00:00:00\n",
      "2013-10-14 00:00:00\n",
      "2013-10-21 00:00:00\n",
      "2013-10-28 00:00:00\n",
      "2013-11-04 00:00:00\n",
      "2013-11-11 00:00:00\n",
      "2013-11-18 00:00:00\n",
      "2013-11-25 00:00:00\n",
      "2013-12-02 00:00:00\n",
      "2013-12-09 00:00:00\n",
      "2013-12-16 00:00:00\n",
      "2013-12-23 00:00:00\n",
      "2013-12-30 00:00:00\n",
      "2014-01-06 00:00:00\n",
      "2014-01-13 00:00:00\n",
      "2014-01-20 00:00:00\n",
      "2014-01-27 00:00:00\n",
      "2014-02-03 00:00:00\n",
      "2014-02-10 00:00:00\n",
      "2014-02-17 00:00:00\n",
      "2014-02-24 00:00:00\n",
      "2014-03-03 00:00:00\n",
      "2014-03-10 00:00:00\n",
      "2014-03-17 00:00:00\n",
      "2014-03-24 00:00:00\n",
      "2014-03-31 00:00:00\n",
      "2014-04-07 00:00:00\n",
      "2014-04-14 00:00:00\n",
      "2014-04-21 00:00:00\n",
      "2014-04-28 00:00:00\n",
      "2014-05-05 00:00:00\n",
      "2014-05-12 00:00:00\n",
      "2014-05-19 00:00:00\n",
      "2014-05-26 00:00:00\n",
      "2014-06-02 00:00:00\n",
      "2014-06-09 00:00:00\n",
      "2014-06-16 00:00:00\n",
      "2014-06-23 00:00:00\n",
      "2014-06-30 00:00:00\n",
      "2014-07-07 00:00:00\n",
      "2014-07-14 00:00:00\n",
      "2014-07-21 00:00:00\n",
      "2014-07-28 00:00:00\n",
      "2014-08-04 00:00:00\n",
      "2014-08-11 00:00:00\n",
      "2014-08-18 00:00:00\n",
      "2014-08-25 00:00:00\n",
      "2014-09-01 00:00:00\n",
      "2014-09-08 00:00:00\n",
      "2014-09-15 00:00:00\n",
      "2014-09-22 00:00:00\n",
      "2014-09-29 00:00:00\n",
      "2014-10-06 00:00:00\n",
      "2014-10-13 00:00:00\n",
      "2014-10-20 00:00:00\n",
      "2014-10-27 00:00:00\n",
      "2014-11-03 00:00:00\n",
      "2014-11-10 00:00:00\n",
      "2014-11-17 00:00:00\n",
      "2014-11-24 00:00:00\n",
      "2014-12-01 00:00:00\n",
      "2014-12-08 00:00:00\n",
      "2014-12-15 00:00:00\n",
      "2014-12-22 00:00:00\n",
      "2014-12-29 00:00:00\n",
      "2015-01-05 00:00:00\n",
      "2015-01-12 00:00:00\n",
      "2015-01-19 00:00:00\n",
      "2015-01-26 00:00:00\n",
      "2015-02-02 00:00:00\n",
      "2015-02-09 00:00:00\n",
      "2015-02-16 00:00:00\n",
      "2015-02-23 00:00:00\n",
      "2015-03-02 00:00:00\n",
      "2015-03-09 00:00:00\n",
      "2015-03-16 00:00:00\n",
      "2015-03-23 00:00:00\n",
      "2015-03-30 00:00:00\n",
      "2015-04-06 00:00:00\n",
      "2015-04-13 00:00:00\n",
      "2015-04-20 00:00:00\n",
      "2015-04-27 00:00:00\n",
      "2015-05-04 00:00:00\n",
      "2015-05-11 00:00:00\n",
      "2015-05-18 00:00:00\n",
      "2015-05-25 00:00:00\n",
      "2015-06-01 00:00:00\n",
      "2015-06-08 00:00:00\n",
      "2015-06-15 00:00:00\n",
      "2015-06-22 00:00:00\n",
      "2015-06-29 00:00:00\n",
      "2015-07-06 00:00:00\n",
      "2015-07-13 00:00:00\n",
      "2015-07-20 00:00:00\n",
      "2015-07-27 00:00:00\n",
      "2015-08-03 00:00:00\n",
      "2015-08-10 00:00:00\n",
      "2015-08-17 00:00:00\n",
      "2015-08-24 00:00:00\n",
      "2015-08-31 00:00:00\n",
      "2015-09-07 00:00:00\n",
      "2015-09-14 00:00:00\n",
      "2015-09-21 00:00:00\n",
      "2015-09-28 00:00:00\n",
      "2015-10-05 00:00:00\n",
      "2015-10-12 00:00:00\n",
      "2015-10-19 00:00:00\n",
      "2015-10-26 00:00:00\n",
      "2015-11-02 00:00:00\n",
      "2015-11-09 00:00:00\n",
      "2015-11-16 00:00:00\n",
      "2015-11-23 00:00:00\n",
      "2015-11-30 00:00:00\n",
      "2015-12-07 00:00:00\n",
      "2015-12-14 00:00:00\n",
      "2015-12-21 00:00:00\n",
      "2015-12-28 00:00:00\n",
      "2016-01-04 00:00:00\n",
      "2016-01-11 00:00:00\n",
      "2016-01-18 00:00:00\n",
      "2016-01-25 00:00:00\n",
      "2016-02-01 00:00:00\n",
      "2016-02-08 00:00:00\n",
      "2016-02-15 00:00:00\n",
      "2016-02-22 00:00:00\n",
      "2016-02-29 00:00:00\n",
      "2016-03-07 00:00:00\n",
      "2016-03-14 00:00:00\n",
      "2016-03-21 00:00:00\n",
      "2016-03-28 00:00:00\n",
      "2016-04-04 00:00:00\n",
      "2016-04-11 00:00:00\n",
      "2016-04-18 00:00:00\n",
      "2016-04-25 00:00:00\n",
      "2016-05-02 00:00:00\n",
      "2016-05-09 00:00:00\n",
      "2016-05-16 00:00:00\n",
      "2016-05-23 00:00:00\n",
      "2016-05-30 00:00:00\n",
      "2016-06-06 00:00:00\n",
      "2016-06-13 00:00:00\n",
      "2016-06-20 00:00:00\n",
      "2016-06-27 00:00:00\n",
      "2016-07-04 00:00:00\n",
      "2016-07-11 00:00:00\n",
      "2016-07-18 00:00:00\n",
      "2016-07-25 00:00:00\n",
      "2016-08-01 00:00:00\n",
      "2016-08-08 00:00:00\n",
      "2016-08-15 00:00:00\n",
      "2016-08-22 00:00:00\n",
      "2016-08-29 00:00:00\n",
      "2016-09-05 00:00:00\n",
      "2016-09-12 00:00:00\n",
      "2016-09-19 00:00:00\n",
      "2016-09-26 00:00:00\n",
      "2016-10-03 00:00:00\n",
      "2016-10-10 00:00:00\n",
      "2016-10-17 00:00:00\n",
      "2016-10-24 00:00:00\n",
      "2016-10-31 00:00:00\n",
      "2016-11-07 00:00:00\n",
      "2016-11-14 00:00:00\n",
      "2016-11-21 00:00:00\n",
      "2016-11-28 00:00:00\n",
      "2016-12-05 00:00:00\n",
      "2016-12-12 00:00:00\n",
      "2016-12-19 00:00:00\n",
      "2016-12-26 00:00:00\n",
      "2017-01-02 00:00:00\n",
      "2017-01-09 00:00:00\n",
      "2017-01-16 00:00:00\n",
      "2017-01-23 00:00:00\n",
      "2017-01-30 00:00:00\n",
      "2017-02-06 00:00:00\n",
      "2017-02-13 00:00:00\n",
      "2017-02-20 00:00:00\n",
      "2017-02-27 00:00:00\n",
      "2017-03-06 00:00:00\n",
      "2017-03-13 00:00:00\n",
      "2017-03-20 00:00:00\n",
      "2017-03-27 00:00:00\n",
      "2017-04-03 00:00:00\n",
      "2017-04-10 00:00:00\n",
      "2017-04-17 00:00:00\n",
      "2017-04-24 00:00:00\n",
      "2017-05-01 00:00:00\n",
      "2017-05-08 00:00:00\n",
      "2017-05-15 00:00:00\n",
      "2017-05-22 00:00:00\n",
      "2017-05-29 00:00:00\n",
      "2017-06-05 00:00:00\n",
      "2017-06-12 00:00:00\n",
      "2017-06-19 00:00:00\n",
      "2017-06-26 00:00:00\n",
      "2017-07-03 00:00:00\n",
      "2017-07-10 00:00:00\n",
      "2017-07-17 00:00:00\n",
      "2017-07-24 00:00:00\n",
      "2017-07-31 00:00:00\n",
      "2017-08-07 00:00:00\n",
      "2017-08-14 00:00:00\n",
      "2017-08-21 00:00:00\n",
      "2017-08-28 00:00:00\n",
      "2017-09-04 00:00:00\n",
      "2017-09-11 00:00:00\n",
      "2017-09-18 00:00:00\n",
      "2017-09-25 00:00:00\n",
      "2017-10-02 00:00:00\n",
      "2017-10-09 00:00:00\n",
      "2017-10-16 00:00:00\n",
      "2017-10-23 00:00:00\n",
      "2017-10-30 00:00:00\n",
      "2017-11-06 00:00:00\n",
      "2017-11-13 00:00:00\n",
      "2017-11-20 00:00:00\n",
      "2017-11-27 00:00:00\n",
      "2017-12-04 00:00:00\n",
      "2017-12-11 00:00:00\n",
      "2017-12-18 00:00:00\n",
      "2017-12-25 00:00:00\n",
      "2018-01-01 00:00:00\n",
      "2018-01-08 00:00:00\n",
      "2018-01-15 00:00:00\n",
      "2018-01-22 00:00:00\n",
      "2018-01-29 00:00:00\n",
      "2018-02-05 00:00:00\n",
      "2018-02-12 00:00:00\n",
      "2018-02-19 00:00:00\n",
      "2018-02-26 00:00:00\n",
      "2018-03-05 00:00:00\n",
      "2018-03-12 00:00:00\n",
      "2018-03-19 00:00:00\n",
      "2018-03-26 00:00:00\n",
      "2018-04-02 00:00:00\n",
      "2018-04-09 00:00:00\n",
      "2018-04-16 00:00:00\n",
      "2018-04-23 00:00:00\n",
      "2018-04-30 00:00:00\n",
      "2018-05-07 00:00:00\n",
      "2018-05-14 00:00:00\n",
      "2018-05-21 00:00:00\n",
      "2018-05-28 00:00:00\n",
      "2018-06-04 00:00:00\n",
      "2018-06-11 00:00:00\n",
      "2018-06-18 00:00:00\n",
      "2018-06-25 00:00:00\n",
      "2018-07-02 00:00:00\n",
      "2018-07-09 00:00:00\n",
      "2018-07-16 00:00:00\n",
      "2018-07-23 00:00:00\n",
      "2018-07-30 00:00:00\n",
      "2018-08-06 00:00:00\n",
      "2018-08-13 00:00:00\n",
      "2018-08-20 00:00:00\n",
      "2018-08-27 00:00:00\n",
      "2018-09-03 00:00:00\n",
      "2018-09-10 00:00:00\n",
      "2018-09-17 00:00:00\n",
      "2018-09-24 00:00:00\n",
      "2018-10-01 00:00:00\n",
      "2018-10-08 00:00:00\n",
      "2018-10-15 00:00:00\n",
      "2018-10-22 00:00:00\n",
      "2018-10-29 00:00:00\n",
      "2018-11-05 00:00:00\n",
      "2018-11-12 00:00:00\n",
      "2018-11-19 00:00:00\n",
      "2018-11-26 00:00:00\n",
      "2018-12-03 00:00:00\n",
      "2018-12-10 00:00:00\n",
      "2018-12-17 00:00:00\n",
      "2018-12-24 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "2019-01-07 00:00:00\n",
      "2019-01-14 00:00:00\n",
      "2019-01-21 00:00:00\n",
      "2019-01-28 00:00:00\n",
      "2019-02-04 00:00:00\n",
      "2019-02-11 00:00:00\n",
      "2019-02-18 00:00:00\n",
      "2019-02-25 00:00:00\n",
      "2019-03-04 00:00:00\n",
      "2019-03-11 00:00:00\n",
      "2019-03-18 00:00:00\n",
      "2019-03-25 00:00:00\n",
      "2019-04-01 00:00:00\n",
      "2019-04-08 00:00:00\n",
      "2019-04-15 00:00:00\n",
      "2019-04-22 00:00:00\n",
      "2019-04-29 00:00:00\n",
      "2019-05-06 00:00:00\n",
      "2019-05-13 00:00:00\n",
      "2019-05-20 00:00:00\n",
      "2019-05-27 00:00:00\n",
      "2019-06-03 00:00:00\n",
      "2019-06-10 00:00:00\n",
      "2019-06-17 00:00:00\n",
      "2019-06-24 00:00:00\n",
      "2019-07-01 00:00:00\n",
      "2019-07-08 00:00:00\n",
      "2019-07-15 00:00:00\n",
      "2019-07-22 00:00:00\n",
      "2019-07-29 00:00:00\n",
      "2019-08-05 00:00:00\n",
      "2019-08-12 00:00:00\n",
      "2019-08-19 00:00:00\n",
      "2019-08-26 00:00:00\n",
      "2019-09-02 00:00:00\n",
      "2019-09-09 00:00:00\n",
      "2019-09-16 00:00:00\n",
      "2019-09-23 00:00:00\n",
      "2019-09-30 00:00:00\n",
      "2019-10-07 00:00:00\n",
      "2019-10-14 00:00:00\n",
      "2019-10-21 00:00:00\n",
      "2019-10-28 00:00:00\n",
      "2019-11-04 00:00:00\n",
      "2019-11-11 00:00:00\n",
      "2019-11-18 00:00:00\n",
      "2019-11-25 00:00:00\n",
      "2019-12-02 00:00:00\n",
      "2019-12-09 00:00:00\n",
      "2019-12-16 00:00:00\n",
      "2019-12-23 00:00:00\n",
      "2019-12-30 00:00:00\n",
      "2020-01-06 00:00:00\n",
      "2020-01-13 00:00:00\n",
      "2020-01-20 00:00:00\n",
      "2020-01-27 00:00:00\n",
      "2020-02-03 00:00:00\n",
      "2020-02-10 00:00:00\n",
      "2020-02-17 00:00:00\n",
      "2020-02-24 00:00:00\n",
      "2020-03-02 00:00:00\n",
      "2020-03-09 00:00:00\n",
      "2020-03-16 00:00:00\n",
      "2020-03-23 00:00:00\n",
      "2020-03-30 00:00:00\n",
      "2020-04-06 00:00:00\n",
      "2020-04-13 00:00:00\n",
      "2020-04-20 00:00:00\n",
      "2020-04-27 00:00:00\n",
      "2020-05-04 00:00:00\n",
      "2020-05-11 00:00:00\n",
      "2020-05-18 00:00:00\n",
      "2020-05-25 00:00:00\n",
      "2020-06-01 00:00:00\n",
      "2020-06-08 00:00:00\n",
      "2020-06-15 00:00:00\n",
      "2020-06-22 00:00:00\n",
      "2020-06-29 00:00:00\n",
      "2020-07-06 00:00:00\n",
      "2020-07-13 00:00:00\n",
      "2020-07-20 00:00:00\n",
      "2020-07-27 00:00:00\n",
      "2020-08-03 00:00:00\n",
      "2020-08-10 00:00:00\n",
      "2020-08-17 00:00:00\n",
      "2020-08-24 00:00:00\n",
      "2020-08-31 00:00:00\n",
      "2020-09-07 00:00:00\n",
      "2020-09-14 00:00:00\n",
      "2020-09-21 00:00:00\n",
      "2020-09-28 00:00:00\n",
      "2020-10-05 00:00:00\n",
      "2020-10-12 00:00:00\n",
      "2020-10-19 00:00:00\n",
      "2020-10-26 00:00:00\n",
      "2020-11-02 00:00:00\n",
      "2020-11-09 00:00:00\n",
      "2020-11-16 00:00:00\n",
      "2020-11-23 00:00:00\n",
      "2020-11-30 00:00:00\n",
      "2020-12-07 00:00:00\n",
      "2020-12-14 00:00:00\n",
      "2020-12-21 00:00:00\n",
      "2020-12-28 00:00:00\n",
      "2021-01-04 00:00:00\n",
      "2021-01-11 00:00:00\n",
      "2021-01-18 00:00:00\n",
      "2021-01-25 00:00:00\n",
      "2021-02-01 00:00:00\n",
      "2021-02-08 00:00:00\n",
      "2021-02-15 00:00:00\n",
      "2021-02-22 00:00:00\n",
      "2021-03-01 00:00:00\n",
      "2021-03-08 00:00:00\n",
      "2021-03-15 00:00:00\n",
      "2021-03-22 00:00:00\n",
      "2021-03-29 00:00:00\n",
      "2021-04-05 00:00:00\n",
      "2021-04-12 00:00:00\n",
      "2021-04-19 00:00:00\n",
      "2021-04-26 00:00:00\n",
      "2021-05-03 00:00:00\n",
      "2021-05-10 00:00:00\n",
      "2021-05-17 00:00:00\n",
      "2021-05-24 00:00:00\n",
      "2021-05-31 00:00:00\n",
      "2021-06-07 00:00:00\n",
      "2021-06-14 00:00:00\n",
      "2021-06-21 00:00:00\n",
      "2021-06-28 00:00:00\n",
      "2021-07-05 00:00:00\n",
      "2021-07-12 00:00:00\n",
      "2021-07-19 00:00:00\n",
      "2021-07-26 00:00:00\n",
      "2021-08-02 00:00:00\n",
      "2021-08-09 00:00:00\n",
      "2021-08-16 00:00:00\n",
      "2021-08-23 00:00:00\n",
      "2021-08-30 00:00:00\n",
      "2021-09-06 00:00:00\n",
      "2021-09-13 00:00:00\n",
      "2021-09-20 00:00:00\n",
      "2021-09-27 00:00:00\n",
      "2021-10-04 00:00:00\n",
      "2021-10-11 00:00:00\n",
      "2021-10-18 00:00:00\n",
      "2021-10-25 00:00:00\n",
      "2021-11-01 00:00:00\n",
      "2021-11-08 00:00:00\n",
      "2021-11-15 00:00:00\n",
      "2021-11-22 00:00:00\n",
      "2021-11-29 00:00:00\n",
      "2021-12-06 00:00:00\n",
      "2021-12-13 00:00:00\n",
      "2021-12-20 00:00:00\n",
      "2021-12-27 00:00:00\n",
      "2022-01-03 00:00:00\n",
      "2022-01-10 00:00:00\n",
      "2022-01-17 00:00:00\n",
      "2022-01-24 00:00:00\n",
      "2022-01-31 00:00:00\n",
      "2022-02-07 00:00:00\n",
      "2022-02-14 00:00:00\n",
      "2022-02-21 00:00:00\n",
      "2022-02-28 00:00:00\n",
      "2022-03-07 00:00:00\n",
      "2022-03-14 00:00:00\n",
      "2022-03-21 00:00:00\n",
      "2022-03-28 00:00:00\n",
      "2022-04-04 00:00:00\n",
      "2022-04-11 00:00:00\n",
      "2022-04-18 00:00:00\n",
      "2022-04-25 00:00:00\n",
      "2022-05-02 00:00:00\n",
      "2022-05-09 00:00:00\n",
      "2022-05-16 00:00:00\n",
      "2022-05-23 00:00:00\n",
      "2022-05-30 00:00:00\n",
      "2022-06-06 00:00:00\n",
      "2022-06-13 00:00:00\n",
      "2022-06-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "pred_date_li = []\n",
    "for q in raw_coll.find({'dbcode':dbcode, \"model_para\":{'freq': 'W', 'package': 'pytorch', 'dat_trans': 'log return', 'input_len':enc_len, 'output_len':pred_len},\n",
    "                      \"search_cols\": search_cols}):\n",
    "    print(q['pred_date'])\n",
    "    pred_date_li += [q['pred_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "814bbd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2021-06-14 00:00:00'),\n",
       " Timestamp('2021-07-19 00:00:00'),\n",
       " Timestamp('2021-08-16 00:00:00'),\n",
       " Timestamp('2021-09-20 00:00:00'),\n",
       " Timestamp('2021-10-18 00:00:00'),\n",
       " Timestamp('2021-11-15 00:00:00'),\n",
       " Timestamp('2021-12-20 00:00:00'),\n",
       " Timestamp('2022-01-17 00:00:00'),\n",
       " Timestamp('2022-02-14 00:00:00'),\n",
       " Timestamp('2022-03-14 00:00:00'),\n",
       " Timestamp('2022-04-18 00:00:00'),\n",
       " Timestamp('2022-05-16 00:00:00'),\n",
       " Timestamp('2022-06-20 00:00:00')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_li = list(pd.Series(pred_date_li)[pd.Series(pred_date_li).map(lambda x: x>=datetime.datetime(2021, 6, 14, 0, 0) and 14<=x.day<=20)]) #추후 변경 필요할지도.. 21일 포함 X\n",
    "test_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "662070e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2021-06-14 00:00:00'),\n",
       " Timestamp('2021-07-19 00:00:00'),\n",
       " Timestamp('2021-08-16 00:00:00'),\n",
       " Timestamp('2021-09-20 00:00:00'),\n",
       " Timestamp('2021-10-18 00:00:00'),\n",
       " Timestamp('2021-11-15 00:00:00'),\n",
       " Timestamp('2021-12-20 00:00:00'),\n",
       " Timestamp('2022-01-17 00:00:00'),\n",
       " Timestamp('2022-02-14 00:00:00'),\n",
       " Timestamp('2022-03-14 00:00:00'),\n",
       " Timestamp('2022-04-18 00:00:00'),\n",
       " Timestamp('2022-05-16 00:00:00')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_li[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "829ee93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      7.165842\n",
      "1     11.953381\n",
      "2     13.288009\n",
      "3     16.554539\n",
      "4     16.596156\n",
      "5     15.953361\n",
      "6     16.970878\n",
      "7     19.115367\n",
      "8     26.103310\n",
      "9           NaN\n",
      "10          NaN\n",
      "11          NaN\n",
      "dtype: float64\n",
      "0      6.275652\n",
      "1     10.339143\n",
      "2     12.190727\n",
      "3     16.826670\n",
      "4     21.196561\n",
      "5     28.430582\n",
      "6     34.552886\n",
      "7     41.526685\n",
      "8     51.693740\n",
      "9           NaN\n",
      "10          NaN\n",
      "11          NaN\n",
      "dtype: float64\n",
      "0      6.582683\n",
      "1     11.737501\n",
      "2     15.188324\n",
      "3     20.703450\n",
      "4     27.653364\n",
      "5     35.833501\n",
      "6     44.939722\n",
      "7     55.870093\n",
      "8     69.094601\n",
      "9           NaN\n",
      "10          NaN\n",
      "11          NaN\n",
      "dtype: float64\n",
      "0      5.939049\n",
      "1      9.463539\n",
      "2     11.745125\n",
      "3     13.241717\n",
      "4     15.909302\n",
      "5     24.186912\n",
      "6     31.584475\n",
      "7     40.047840\n",
      "8     50.422606\n",
      "9           NaN\n",
      "10          NaN\n",
      "11          NaN\n",
      "dtype: float64\n",
      "0       7.432552\n",
      "1      15.397275\n",
      "2      22.373119\n",
      "3      29.378131\n",
      "4      41.617621\n",
      "5      55.148799\n",
      "6      71.792857\n",
      "7      90.773222\n",
      "8     118.987810\n",
      "9            NaN\n",
      "10           NaN\n",
      "11           NaN\n",
      "dtype: float64\n",
      "0       8.113434\n",
      "1      15.959777\n",
      "2      25.449946\n",
      "3      35.395829\n",
      "4      49.340663\n",
      "5      64.860669\n",
      "6      82.421516\n",
      "7     103.073995\n",
      "8     127.703305\n",
      "9            NaN\n",
      "10           NaN\n",
      "11           NaN\n",
      "dtype: float64\n",
      "0      5.754248\n",
      "1      9.890796\n",
      "2     14.642639\n",
      "3     22.221959\n",
      "4     31.771413\n",
      "5     42.519091\n",
      "6     53.245864\n",
      "7     64.181171\n",
      "8     76.603284\n",
      "9           NaN\n",
      "10          NaN\n",
      "11          NaN\n",
      "dtype: float64\n",
      "0      6.204299\n",
      "1      9.973703\n",
      "2     11.424125\n",
      "3     14.268740\n",
      "4     16.407646\n",
      "5     18.762594\n",
      "6     21.802493\n",
      "7     23.517592\n",
      "8     23.891490\n",
      "9           NaN\n",
      "10          NaN\n",
      "11          NaN\n",
      "dtype: float64\n",
      "0      5.801197\n",
      "1      8.748681\n",
      "2     11.072979\n",
      "3     11.824336\n",
      "4     16.412735\n",
      "5     19.343563\n",
      "6     22.959464\n",
      "7     24.890799\n",
      "8     29.422566\n",
      "9           NaN\n",
      "10          NaN\n",
      "11          NaN\n",
      "dtype: float64\n",
      "0      6.140493\n",
      "1      9.786551\n",
      "2     11.386431\n",
      "3     13.930492\n",
      "4     16.205622\n",
      "5     18.810097\n",
      "6     21.622214\n",
      "7     23.664825\n",
      "8     24.068886\n",
      "9           NaN\n",
      "10          NaN\n",
      "11          NaN\n",
      "dtype: float64\n",
      "0      5.944123\n",
      "1      9.760347\n",
      "2     11.580772\n",
      "3     14.938208\n",
      "4     19.454353\n",
      "5     26.007399\n",
      "6     33.388664\n",
      "7     41.287474\n",
      "8     51.949347\n",
      "9           NaN\n",
      "10          NaN\n",
      "11          NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "test_score = pd.DataFrame()\n",
    "\n",
    "for j in range(1,12,1):\n",
    "    mape_record = pd.Series([0]*12)\n",
    "    for k in test_li[:12]:\n",
    "        sample2 = raw_coll.find_one({'dbcode':dbcode, \"model_para\":{'freq': 'W', 'package': 'pytorch', 'dat_trans': 'log return', 'input_len':enc_len, 'output_len':pred_len},\n",
    "                      \"search_cols\": search_cols, \"pred_date\":k})\n",
    "        temp_record = dat_ave(df_comp(sample2['pred_val']))[1:13]\n",
    "        temp_record['average'] = temp_record.iloc[:,range(1,11,1)].apply(np.average,axis=1)\n",
    "        iron = pr_q_slim(dbcode)\n",
    "        iron = dat_ave(iron)\n",
    "        temp_record2 = pd.merge(temp_record,iron,how='left',on='Date')\n",
    "        mape_record += abs((temp_record2.iloc[:,j] - temp_record2.iloc[:,-1]) / temp_record2.iloc[:,-1]) * 100 #mape of 1M ~ 12M\n",
    "    print(mape_record/12)\n",
    "    test_score = pd.concat([test_score,mape_record/12],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "671a6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score.columns = list(df_comp(q['pred_val']).columns[1:]) + ['average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2e1c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score.index = [str(k)+\"M spot\" for k in range(1,13,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5bdff5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf1_labellen8</th>\n",
       "      <th>tf2_labellen4</th>\n",
       "      <th>tf3_labellen12</th>\n",
       "      <th>tf4_labellen4</th>\n",
       "      <th>tf5_labellen4</th>\n",
       "      <th>tf6_labellen8</th>\n",
       "      <th>tf7_labellen8</th>\n",
       "      <th>tf8_labellen12</th>\n",
       "      <th>tf9_labellen4</th>\n",
       "      <th>tf10_labellen0</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1M spot</th>\n",
       "      <td>7.165842</td>\n",
       "      <td>6.275652</td>\n",
       "      <td>6.582683</td>\n",
       "      <td>5.939049</td>\n",
       "      <td>7.432552</td>\n",
       "      <td>8.113434</td>\n",
       "      <td>5.754248</td>\n",
       "      <td>6.204299</td>\n",
       "      <td>5.801197</td>\n",
       "      <td>6.140493</td>\n",
       "      <td>5.944123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2M spot</th>\n",
       "      <td>11.953381</td>\n",
       "      <td>10.339143</td>\n",
       "      <td>11.737501</td>\n",
       "      <td>9.463539</td>\n",
       "      <td>15.397275</td>\n",
       "      <td>15.959777</td>\n",
       "      <td>9.890796</td>\n",
       "      <td>9.973703</td>\n",
       "      <td>8.748681</td>\n",
       "      <td>9.786551</td>\n",
       "      <td>9.760347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3M spot</th>\n",
       "      <td>13.288009</td>\n",
       "      <td>12.190727</td>\n",
       "      <td>15.188324</td>\n",
       "      <td>11.745125</td>\n",
       "      <td>22.373119</td>\n",
       "      <td>25.449946</td>\n",
       "      <td>14.642639</td>\n",
       "      <td>11.424125</td>\n",
       "      <td>11.072979</td>\n",
       "      <td>11.386431</td>\n",
       "      <td>11.580772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4M spot</th>\n",
       "      <td>16.554539</td>\n",
       "      <td>16.826670</td>\n",
       "      <td>20.703450</td>\n",
       "      <td>13.241717</td>\n",
       "      <td>29.378131</td>\n",
       "      <td>35.395829</td>\n",
       "      <td>22.221959</td>\n",
       "      <td>14.268740</td>\n",
       "      <td>11.824336</td>\n",
       "      <td>13.930492</td>\n",
       "      <td>14.938208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5M spot</th>\n",
       "      <td>16.596156</td>\n",
       "      <td>21.196561</td>\n",
       "      <td>27.653364</td>\n",
       "      <td>15.909302</td>\n",
       "      <td>41.617621</td>\n",
       "      <td>49.340663</td>\n",
       "      <td>31.771413</td>\n",
       "      <td>16.407646</td>\n",
       "      <td>16.412735</td>\n",
       "      <td>16.205622</td>\n",
       "      <td>19.454353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6M spot</th>\n",
       "      <td>15.953361</td>\n",
       "      <td>28.430582</td>\n",
       "      <td>35.833501</td>\n",
       "      <td>24.186912</td>\n",
       "      <td>55.148799</td>\n",
       "      <td>64.860669</td>\n",
       "      <td>42.519091</td>\n",
       "      <td>18.762594</td>\n",
       "      <td>19.343563</td>\n",
       "      <td>18.810097</td>\n",
       "      <td>26.007399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7M spot</th>\n",
       "      <td>16.970878</td>\n",
       "      <td>34.552886</td>\n",
       "      <td>44.939722</td>\n",
       "      <td>31.584475</td>\n",
       "      <td>71.792857</td>\n",
       "      <td>82.421516</td>\n",
       "      <td>53.245864</td>\n",
       "      <td>21.802493</td>\n",
       "      <td>22.959464</td>\n",
       "      <td>21.622214</td>\n",
       "      <td>33.388664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8M spot</th>\n",
       "      <td>19.115367</td>\n",
       "      <td>41.526685</td>\n",
       "      <td>55.870093</td>\n",
       "      <td>40.047840</td>\n",
       "      <td>90.773222</td>\n",
       "      <td>103.073995</td>\n",
       "      <td>64.181171</td>\n",
       "      <td>23.517592</td>\n",
       "      <td>24.890799</td>\n",
       "      <td>23.664825</td>\n",
       "      <td>41.287474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9M spot</th>\n",
       "      <td>26.103310</td>\n",
       "      <td>51.693740</td>\n",
       "      <td>69.094601</td>\n",
       "      <td>50.422606</td>\n",
       "      <td>118.987810</td>\n",
       "      <td>127.703305</td>\n",
       "      <td>76.603284</td>\n",
       "      <td>23.891490</td>\n",
       "      <td>29.422566</td>\n",
       "      <td>24.068886</td>\n",
       "      <td>51.949347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10M spot</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11M spot</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12M spot</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tf1_labellen8  tf2_labellen4  tf3_labellen12  tf4_labellen4  \\\n",
       "1M spot        7.165842       6.275652        6.582683       5.939049   \n",
       "2M spot       11.953381      10.339143       11.737501       9.463539   \n",
       "3M spot       13.288009      12.190727       15.188324      11.745125   \n",
       "4M spot       16.554539      16.826670       20.703450      13.241717   \n",
       "5M spot       16.596156      21.196561       27.653364      15.909302   \n",
       "6M spot       15.953361      28.430582       35.833501      24.186912   \n",
       "7M spot       16.970878      34.552886       44.939722      31.584475   \n",
       "8M spot       19.115367      41.526685       55.870093      40.047840   \n",
       "9M spot       26.103310      51.693740       69.094601      50.422606   \n",
       "10M spot            NaN            NaN             NaN            NaN   \n",
       "11M spot            NaN            NaN             NaN            NaN   \n",
       "12M spot            NaN            NaN             NaN            NaN   \n",
       "\n",
       "          tf5_labellen4  tf6_labellen8  tf7_labellen8  tf8_labellen12  \\\n",
       "1M spot        7.432552       8.113434       5.754248        6.204299   \n",
       "2M spot       15.397275      15.959777       9.890796        9.973703   \n",
       "3M spot       22.373119      25.449946      14.642639       11.424125   \n",
       "4M spot       29.378131      35.395829      22.221959       14.268740   \n",
       "5M spot       41.617621      49.340663      31.771413       16.407646   \n",
       "6M spot       55.148799      64.860669      42.519091       18.762594   \n",
       "7M spot       71.792857      82.421516      53.245864       21.802493   \n",
       "8M spot       90.773222     103.073995      64.181171       23.517592   \n",
       "9M spot      118.987810     127.703305      76.603284       23.891490   \n",
       "10M spot            NaN            NaN            NaN             NaN   \n",
       "11M spot            NaN            NaN            NaN             NaN   \n",
       "12M spot            NaN            NaN            NaN             NaN   \n",
       "\n",
       "          tf9_labellen4  tf10_labellen0    average  \n",
       "1M spot        5.801197        6.140493   5.944123  \n",
       "2M spot        8.748681        9.786551   9.760347  \n",
       "3M spot       11.072979       11.386431  11.580772  \n",
       "4M spot       11.824336       13.930492  14.938208  \n",
       "5M spot       16.412735       16.205622  19.454353  \n",
       "6M spot       19.343563       18.810097  26.007399  \n",
       "7M spot       22.959464       21.622214  33.388664  \n",
       "8M spot       24.890799       23.664825  41.287474  \n",
       "9M spot       29.422566       24.068886  51.949347  \n",
       "10M spot            NaN             NaN        NaN  \n",
       "11M spot            NaN             NaN        NaN  \n",
       "12M spot            NaN             NaN        NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ccd93",
   "metadata": {},
   "source": [
    "## 모델 저장 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "083b80fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id',\n",
       " 'model_type',\n",
       " 'model_writer',\n",
       " 'ensemble',\n",
       " 'reg_date',\n",
       " 'model_para',\n",
       " 'item_name',\n",
       " 'item_spec',\n",
       " 'dbcode',\n",
       " 'search_cols',\n",
       " 'pred_val',\n",
       " 'pred_date']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4b4e273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('63f443cdf777b79e95f90d7a')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[\"_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fd2a597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRANSFORMER'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[\"model_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e0c711f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KMS'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[\"model_writer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62c38780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[\"ensemble\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b28cfef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 2, 21, 0, 0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[\"reg_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5df60d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'freq': 'W',\n",
       " 'package': 'pytorch',\n",
       " 'dat_trans': 'log return',\n",
       " 'input_len': 104,\n",
       " 'output_len': 17}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[\"model_para\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73e78def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'브렌트유'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[\"item_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "806c9eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[\"item_spec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca1fd909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02-01-01-00-02-00-1301-NO'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[\"dbcode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "885378fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02-03-01-E2-01-00-USA-00-57-05',\n",
       " '02-01-01-ED-00-00-USA-00-57-04',\n",
       " '02-01-01-ED-00-00-922-00-57-04',\n",
       " '01-02-02-03-00-05-USA-00-19-06',\n",
       " '2_01_03_03_03_00_05_USA_00_134_06']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[\"search_cols\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87f1af3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>tf1_labellen8</th>\n",
       "      <th>tf2_labellen4</th>\n",
       "      <th>tf3_labellen12</th>\n",
       "      <th>tf4_labellen4</th>\n",
       "      <th>tf5_labellen4</th>\n",
       "      <th>tf6_labellen8</th>\n",
       "      <th>tf7_labellen8</th>\n",
       "      <th>tf8_labellen12</th>\n",
       "      <th>tf9_labellen4</th>\n",
       "      <th>tf10_labellen0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>113.401576</td>\n",
       "      <td>113.717104</td>\n",
       "      <td>111.887484</td>\n",
       "      <td>113.636318</td>\n",
       "      <td>114.586041</td>\n",
       "      <td>112.824350</td>\n",
       "      <td>112.157742</td>\n",
       "      <td>112.703790</td>\n",
       "      <td>112.219870</td>\n",
       "      <td>113.670728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-04</td>\n",
       "      <td>114.888401</td>\n",
       "      <td>115.528613</td>\n",
       "      <td>111.883356</td>\n",
       "      <td>115.291127</td>\n",
       "      <td>117.300917</td>\n",
       "      <td>113.878353</td>\n",
       "      <td>112.381950</td>\n",
       "      <td>113.478875</td>\n",
       "      <td>112.506474</td>\n",
       "      <td>115.434402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-11</td>\n",
       "      <td>116.394720</td>\n",
       "      <td>117.368979</td>\n",
       "      <td>111.908400</td>\n",
       "      <td>116.913749</td>\n",
       "      <td>120.080115</td>\n",
       "      <td>115.095448</td>\n",
       "      <td>112.606624</td>\n",
       "      <td>114.259289</td>\n",
       "      <td>112.793806</td>\n",
       "      <td>117.225438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>117.920788</td>\n",
       "      <td>119.238662</td>\n",
       "      <td>111.954264</td>\n",
       "      <td>118.524347</td>\n",
       "      <td>122.925161</td>\n",
       "      <td>116.453531</td>\n",
       "      <td>112.831761</td>\n",
       "      <td>115.045071</td>\n",
       "      <td>113.081886</td>\n",
       "      <td>119.044262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>119.466868</td>\n",
       "      <td>121.138130</td>\n",
       "      <td>112.015228</td>\n",
       "      <td>120.136024</td>\n",
       "      <td>125.837615</td>\n",
       "      <td>117.932312</td>\n",
       "      <td>113.057354</td>\n",
       "      <td>115.836257</td>\n",
       "      <td>113.370701</td>\n",
       "      <td>120.891310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>121.033216</td>\n",
       "      <td>123.067855</td>\n",
       "      <td>112.088438</td>\n",
       "      <td>121.755583</td>\n",
       "      <td>128.819073</td>\n",
       "      <td>119.507139</td>\n",
       "      <td>113.283405</td>\n",
       "      <td>116.632883</td>\n",
       "      <td>113.660254</td>\n",
       "      <td>122.767013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>122.620104</td>\n",
       "      <td>125.028321</td>\n",
       "      <td>112.173068</td>\n",
       "      <td>123.384558</td>\n",
       "      <td>131.871174</td>\n",
       "      <td>121.166896</td>\n",
       "      <td>113.509915</td>\n",
       "      <td>117.434989</td>\n",
       "      <td>113.950556</td>\n",
       "      <td>124.671826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>124.227794</td>\n",
       "      <td>127.020017</td>\n",
       "      <td>112.264928</td>\n",
       "      <td>125.026399</td>\n",
       "      <td>134.995585</td>\n",
       "      <td>122.903289</td>\n",
       "      <td>113.736881</td>\n",
       "      <td>118.242610</td>\n",
       "      <td>114.241594</td>\n",
       "      <td>126.606186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-08-22</td>\n",
       "      <td>125.856563</td>\n",
       "      <td>129.043437</td>\n",
       "      <td>112.360383</td>\n",
       "      <td>126.686062</td>\n",
       "      <td>138.194021</td>\n",
       "      <td>124.709901</td>\n",
       "      <td>113.964304</td>\n",
       "      <td>119.055786</td>\n",
       "      <td>114.533378</td>\n",
       "      <td>128.570554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>127.506679</td>\n",
       "      <td>131.099094</td>\n",
       "      <td>112.457039</td>\n",
       "      <td>128.366016</td>\n",
       "      <td>141.468239</td>\n",
       "      <td>126.581730</td>\n",
       "      <td>114.192182</td>\n",
       "      <td>119.874554</td>\n",
       "      <td>114.825911</td>\n",
       "      <td>130.565405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>129.178430</td>\n",
       "      <td>133.187498</td>\n",
       "      <td>112.552986</td>\n",
       "      <td>130.065546</td>\n",
       "      <td>144.820031</td>\n",
       "      <td>128.513103</td>\n",
       "      <td>114.420523</td>\n",
       "      <td>120.698953</td>\n",
       "      <td>115.119190</td>\n",
       "      <td>132.591207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>130.872107</td>\n",
       "      <td>135.309169</td>\n",
       "      <td>112.646681</td>\n",
       "      <td>131.785794</td>\n",
       "      <td>148.251238</td>\n",
       "      <td>130.501069</td>\n",
       "      <td>114.649327</td>\n",
       "      <td>121.529021</td>\n",
       "      <td>115.413219</td>\n",
       "      <td>134.648441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>132.587991</td>\n",
       "      <td>137.464639</td>\n",
       "      <td>112.736980</td>\n",
       "      <td>133.527703</td>\n",
       "      <td>151.763739</td>\n",
       "      <td>132.543248</td>\n",
       "      <td>114.878588</td>\n",
       "      <td>122.364798</td>\n",
       "      <td>115.707999</td>\n",
       "      <td>136.737594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>134.326371</td>\n",
       "      <td>139.654445</td>\n",
       "      <td>112.822971</td>\n",
       "      <td>135.293725</td>\n",
       "      <td>155.359462</td>\n",
       "      <td>134.637759</td>\n",
       "      <td>115.108315</td>\n",
       "      <td>123.206323</td>\n",
       "      <td>116.003532</td>\n",
       "      <td>138.859161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>136.087548</td>\n",
       "      <td>141.879135</td>\n",
       "      <td>112.903576</td>\n",
       "      <td>137.085601</td>\n",
       "      <td>159.040379</td>\n",
       "      <td>136.782990</td>\n",
       "      <td>115.338508</td>\n",
       "      <td>124.053635</td>\n",
       "      <td>116.299823</td>\n",
       "      <td>141.013638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-10-10</td>\n",
       "      <td>137.871816</td>\n",
       "      <td>144.139264</td>\n",
       "      <td>112.978016</td>\n",
       "      <td>138.903891</td>\n",
       "      <td>162.808506</td>\n",
       "      <td>138.977787</td>\n",
       "      <td>115.569162</td>\n",
       "      <td>124.906774</td>\n",
       "      <td>116.596875</td>\n",
       "      <td>143.201547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>139.679474</td>\n",
       "      <td>146.435397</td>\n",
       "      <td>113.045771</td>\n",
       "      <td>140.749097</td>\n",
       "      <td>166.665912</td>\n",
       "      <td>141.221274</td>\n",
       "      <td>115.800276</td>\n",
       "      <td>125.765781</td>\n",
       "      <td>116.894681</td>\n",
       "      <td>145.423406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>141.510823</td>\n",
       "      <td>148.768098</td>\n",
       "      <td>113.253972</td>\n",
       "      <td>143.653953</td>\n",
       "      <td>170.614705</td>\n",
       "      <td>142.648630</td>\n",
       "      <td>116.031746</td>\n",
       "      <td>126.630695</td>\n",
       "      <td>117.193259</td>\n",
       "      <td>147.598326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>143.366197</td>\n",
       "      <td>151.137968</td>\n",
       "      <td>113.507594</td>\n",
       "      <td>146.501733</td>\n",
       "      <td>174.657063</td>\n",
       "      <td>144.282489</td>\n",
       "      <td>116.263696</td>\n",
       "      <td>127.501557</td>\n",
       "      <td>117.492600</td>\n",
       "      <td>149.805774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>145.245892</td>\n",
       "      <td>153.545585</td>\n",
       "      <td>113.792013</td>\n",
       "      <td>149.284406</td>\n",
       "      <td>178.795195</td>\n",
       "      <td>146.083357</td>\n",
       "      <td>116.496130</td>\n",
       "      <td>128.378408</td>\n",
       "      <td>117.792701</td>\n",
       "      <td>152.046241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>147.150236</td>\n",
       "      <td>155.991560</td>\n",
       "      <td>114.097188</td>\n",
       "      <td>152.030119</td>\n",
       "      <td>183.031371</td>\n",
       "      <td>148.043162</td>\n",
       "      <td>116.729046</td>\n",
       "      <td>129.261289</td>\n",
       "      <td>118.093573</td>\n",
       "      <td>154.320211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>149.079545</td>\n",
       "      <td>158.476499</td>\n",
       "      <td>114.415043</td>\n",
       "      <td>154.756545</td>\n",
       "      <td>187.367915</td>\n",
       "      <td>150.155323</td>\n",
       "      <td>116.962435</td>\n",
       "      <td>130.150242</td>\n",
       "      <td>118.395213</td>\n",
       "      <td>156.628190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>151.034148</td>\n",
       "      <td>161.001024</td>\n",
       "      <td>114.741283</td>\n",
       "      <td>157.477870</td>\n",
       "      <td>191.807204</td>\n",
       "      <td>152.399405</td>\n",
       "      <td>117.196301</td>\n",
       "      <td>131.045309</td>\n",
       "      <td>118.697627</td>\n",
       "      <td>158.970686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>153.014370</td>\n",
       "      <td>163.565759</td>\n",
       "      <td>115.071454</td>\n",
       "      <td>160.204483</td>\n",
       "      <td>196.351673</td>\n",
       "      <td>154.753723</td>\n",
       "      <td>117.430642</td>\n",
       "      <td>131.946531</td>\n",
       "      <td>119.000810</td>\n",
       "      <td>161.348216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>155.020555</td>\n",
       "      <td>166.171355</td>\n",
       "      <td>115.402093</td>\n",
       "      <td>162.942833</td>\n",
       "      <td>201.003814</td>\n",
       "      <td>157.206804</td>\n",
       "      <td>117.665465</td>\n",
       "      <td>132.853951</td>\n",
       "      <td>119.304763</td>\n",
       "      <td>163.761309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>157.053052</td>\n",
       "      <td>168.818458</td>\n",
       "      <td>115.730399</td>\n",
       "      <td>165.697829</td>\n",
       "      <td>205.766177</td>\n",
       "      <td>159.751189</td>\n",
       "      <td>117.900755</td>\n",
       "      <td>133.767612</td>\n",
       "      <td>119.609501</td>\n",
       "      <td>166.210492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>159.112198</td>\n",
       "      <td>171.507729</td>\n",
       "      <td>116.054758</td>\n",
       "      <td>168.473259</td>\n",
       "      <td>210.641374</td>\n",
       "      <td>162.381091</td>\n",
       "      <td>118.136514</td>\n",
       "      <td>134.687556</td>\n",
       "      <td>119.915002</td>\n",
       "      <td>168.696305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>161.198346</td>\n",
       "      <td>174.239840</td>\n",
       "      <td>116.375695</td>\n",
       "      <td>171.269717</td>\n",
       "      <td>215.632079</td>\n",
       "      <td>165.092037</td>\n",
       "      <td>118.372756</td>\n",
       "      <td>135.613826</td>\n",
       "      <td>120.221287</td>\n",
       "      <td>171.219289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>163.311846</td>\n",
       "      <td>177.015474</td>\n",
       "      <td>116.691746</td>\n",
       "      <td>174.090156</td>\n",
       "      <td>220.741028</td>\n",
       "      <td>167.879228</td>\n",
       "      <td>118.609481</td>\n",
       "      <td>136.546467</td>\n",
       "      <td>120.528358</td>\n",
       "      <td>173.780007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>165.453051</td>\n",
       "      <td>179.835323</td>\n",
       "      <td>117.001768</td>\n",
       "      <td>176.937709</td>\n",
       "      <td>225.971023</td>\n",
       "      <td>170.739484</td>\n",
       "      <td>118.846686</td>\n",
       "      <td>137.485522</td>\n",
       "      <td>120.836214</td>\n",
       "      <td>176.379022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>167.622331</td>\n",
       "      <td>182.700093</td>\n",
       "      <td>117.304860</td>\n",
       "      <td>179.814599</td>\n",
       "      <td>231.324932</td>\n",
       "      <td>173.671027</td>\n",
       "      <td>119.084366</td>\n",
       "      <td>138.431034</td>\n",
       "      <td>121.144856</td>\n",
       "      <td>179.016908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-01-30</td>\n",
       "      <td>169.820041</td>\n",
       "      <td>185.610498</td>\n",
       "      <td>117.601166</td>\n",
       "      <td>182.722756</td>\n",
       "      <td>236.805690</td>\n",
       "      <td>176.672305</td>\n",
       "      <td>119.322521</td>\n",
       "      <td>139.383049</td>\n",
       "      <td>121.454279</td>\n",
       "      <td>181.694256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>172.046582</td>\n",
       "      <td>188.567260</td>\n",
       "      <td>117.890154</td>\n",
       "      <td>185.663853</td>\n",
       "      <td>242.416304</td>\n",
       "      <td>179.742151</td>\n",
       "      <td>119.561160</td>\n",
       "      <td>140.341612</td>\n",
       "      <td>121.764492</td>\n",
       "      <td>184.411640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>174.302310</td>\n",
       "      <td>191.571129</td>\n",
       "      <td>118.171326</td>\n",
       "      <td>188.639432</td>\n",
       "      <td>248.159849</td>\n",
       "      <td>182.879721</td>\n",
       "      <td>119.800275</td>\n",
       "      <td>141.306766</td>\n",
       "      <td>122.075505</td>\n",
       "      <td>187.169671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>176.587613</td>\n",
       "      <td>194.622844</td>\n",
       "      <td>118.359831</td>\n",
       "      <td>192.762339</td>\n",
       "      <td>254.039475</td>\n",
       "      <td>184.782606</td>\n",
       "      <td>120.039701</td>\n",
       "      <td>142.278558</td>\n",
       "      <td>122.387381</td>\n",
       "      <td>190.232524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>178.902879</td>\n",
       "      <td>197.723172</td>\n",
       "      <td>118.601920</td>\n",
       "      <td>196.802065</td>\n",
       "      <td>260.058407</td>\n",
       "      <td>186.933114</td>\n",
       "      <td>120.279638</td>\n",
       "      <td>143.257034</td>\n",
       "      <td>122.700058</td>\n",
       "      <td>193.345497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023-03-06</td>\n",
       "      <td>181.248501</td>\n",
       "      <td>200.872895</td>\n",
       "      <td>118.874915</td>\n",
       "      <td>200.754397</td>\n",
       "      <td>266.219945</td>\n",
       "      <td>189.281592</td>\n",
       "      <td>120.520075</td>\n",
       "      <td>144.242238</td>\n",
       "      <td>123.013526</td>\n",
       "      <td>196.509406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>183.624882</td>\n",
       "      <td>204.072792</td>\n",
       "      <td>119.170382</td>\n",
       "      <td>204.655905</td>\n",
       "      <td>272.527459</td>\n",
       "      <td>191.821873</td>\n",
       "      <td>120.761001</td>\n",
       "      <td>145.234218</td>\n",
       "      <td>123.327803</td>\n",
       "      <td>199.725100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023-03-20</td>\n",
       "      <td>186.032415</td>\n",
       "      <td>207.323663</td>\n",
       "      <td>119.480655</td>\n",
       "      <td>208.540152</td>\n",
       "      <td>278.984425</td>\n",
       "      <td>194.555591</td>\n",
       "      <td>121.002426</td>\n",
       "      <td>146.233020</td>\n",
       "      <td>123.642868</td>\n",
       "      <td>202.993405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>188.471513</td>\n",
       "      <td>210.626321</td>\n",
       "      <td>119.798369</td>\n",
       "      <td>212.426651</td>\n",
       "      <td>285.594374</td>\n",
       "      <td>197.460036</td>\n",
       "      <td>121.244341</td>\n",
       "      <td>147.238691</td>\n",
       "      <td>123.958749</td>\n",
       "      <td>206.315198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>190.942591</td>\n",
       "      <td>213.981590</td>\n",
       "      <td>120.119276</td>\n",
       "      <td>216.329659</td>\n",
       "      <td>292.360933</td>\n",
       "      <td>200.514457</td>\n",
       "      <td>121.486747</td>\n",
       "      <td>148.251278</td>\n",
       "      <td>124.275436</td>\n",
       "      <td>209.691355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>193.446067</td>\n",
       "      <td>217.390308</td>\n",
       "      <td>120.440232</td>\n",
       "      <td>220.257630</td>\n",
       "      <td>299.287811</td>\n",
       "      <td>203.697049</td>\n",
       "      <td>121.729638</td>\n",
       "      <td>149.270828</td>\n",
       "      <td>124.592933</td>\n",
       "      <td>213.122754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>195.982367</td>\n",
       "      <td>220.853314</td>\n",
       "      <td>120.758388</td>\n",
       "      <td>224.217247</td>\n",
       "      <td>306.378807</td>\n",
       "      <td>206.998096</td>\n",
       "      <td>121.973029</td>\n",
       "      <td>150.297391</td>\n",
       "      <td>124.911241</td>\n",
       "      <td>216.610310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>198.551920</td>\n",
       "      <td>224.371498</td>\n",
       "      <td>121.071655</td>\n",
       "      <td>228.213915</td>\n",
       "      <td>313.637810</td>\n",
       "      <td>210.410485</td>\n",
       "      <td>122.216910</td>\n",
       "      <td>151.331013</td>\n",
       "      <td>125.230359</td>\n",
       "      <td>220.154931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>201.155152</td>\n",
       "      <td>227.945721</td>\n",
       "      <td>121.379082</td>\n",
       "      <td>232.250425</td>\n",
       "      <td>321.068799</td>\n",
       "      <td>213.928666</td>\n",
       "      <td>122.461286</td>\n",
       "      <td>152.371743</td>\n",
       "      <td>125.550288</td>\n",
       "      <td>223.757550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2023-05-08</td>\n",
       "      <td>203.792532</td>\n",
       "      <td>231.576887</td>\n",
       "      <td>121.679573</td>\n",
       "      <td>236.328656</td>\n",
       "      <td>328.675850</td>\n",
       "      <td>217.548084</td>\n",
       "      <td>122.706158</td>\n",
       "      <td>153.419631</td>\n",
       "      <td>125.871038</td>\n",
       "      <td>227.419128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2023-05-15</td>\n",
       "      <td>206.464474</td>\n",
       "      <td>235.265897</td>\n",
       "      <td>121.972411</td>\n",
       "      <td>240.452106</td>\n",
       "      <td>336.463133</td>\n",
       "      <td>221.265207</td>\n",
       "      <td>122.951523</td>\n",
       "      <td>154.474726</td>\n",
       "      <td>126.192607</td>\n",
       "      <td>231.140632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>209.171460</td>\n",
       "      <td>239.013674</td>\n",
       "      <td>122.257918</td>\n",
       "      <td>244.624476</td>\n",
       "      <td>344.434921</td>\n",
       "      <td>225.077341</td>\n",
       "      <td>123.197386</td>\n",
       "      <td>155.537076</td>\n",
       "      <td>126.514995</td>\n",
       "      <td>234.923027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2023-05-29</td>\n",
       "      <td>211.913944</td>\n",
       "      <td>242.821152</td>\n",
       "      <td>122.535341</td>\n",
       "      <td>248.853338</td>\n",
       "      <td>352.595583</td>\n",
       "      <td>228.982400</td>\n",
       "      <td>123.443741</td>\n",
       "      <td>156.606733</td>\n",
       "      <td>126.838206</td>\n",
       "      <td>238.767318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>214.692379</td>\n",
       "      <td>246.689283</td>\n",
       "      <td>122.804118</td>\n",
       "      <td>253.141084</td>\n",
       "      <td>360.949594</td>\n",
       "      <td>232.979478</td>\n",
       "      <td>123.690585</td>\n",
       "      <td>157.683745</td>\n",
       "      <td>127.162242</td>\n",
       "      <td>242.674524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>217.507248</td>\n",
       "      <td>250.619034</td>\n",
       "      <td>123.063817</td>\n",
       "      <td>257.489969</td>\n",
       "      <td>369.501537</td>\n",
       "      <td>237.065805</td>\n",
       "      <td>123.937937</td>\n",
       "      <td>158.768165</td>\n",
       "      <td>127.487107</td>\n",
       "      <td>246.645661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2023-06-19</td>\n",
       "      <td>220.359018</td>\n",
       "      <td>254.611385</td>\n",
       "      <td>123.085117</td>\n",
       "      <td>262.830918</td>\n",
       "      <td>378.256099</td>\n",
       "      <td>239.419005</td>\n",
       "      <td>124.185602</td>\n",
       "      <td>159.860042</td>\n",
       "      <td>127.812778</td>\n",
       "      <td>250.149381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2023-06-26</td>\n",
       "      <td>223.248184</td>\n",
       "      <td>258.667334</td>\n",
       "      <td>123.152069</td>\n",
       "      <td>268.099809</td>\n",
       "      <td>387.218083</td>\n",
       "      <td>242.120595</td>\n",
       "      <td>124.433785</td>\n",
       "      <td>160.959428</td>\n",
       "      <td>128.139285</td>\n",
       "      <td>253.702874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>226.175223</td>\n",
       "      <td>262.787895</td>\n",
       "      <td>123.250812</td>\n",
       "      <td>273.246989</td>\n",
       "      <td>396.392402</td>\n",
       "      <td>245.133283</td>\n",
       "      <td>124.682482</td>\n",
       "      <td>162.066375</td>\n",
       "      <td>128.466623</td>\n",
       "      <td>257.306860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>229.140640</td>\n",
       "      <td>266.974095</td>\n",
       "      <td>123.371251</td>\n",
       "      <td>278.314285</td>\n",
       "      <td>405.784088</td>\n",
       "      <td>248.431184</td>\n",
       "      <td>124.931692</td>\n",
       "      <td>163.180935</td>\n",
       "      <td>128.794793</td>\n",
       "      <td>260.962044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  tf1_labellen8  tf2_labellen4  tf3_labellen12  tf4_labellen4  \\\n",
       "0   2022-06-27     113.401576     113.717104      111.887484     113.636318   \n",
       "1   2022-07-04     114.888401     115.528613      111.883356     115.291127   \n",
       "2   2022-07-11     116.394720     117.368979      111.908400     116.913749   \n",
       "3   2022-07-18     117.920788     119.238662      111.954264     118.524347   \n",
       "4   2022-07-25     119.466868     121.138130      112.015228     120.136024   \n",
       "5   2022-08-01     121.033216     123.067855      112.088438     121.755583   \n",
       "6   2022-08-08     122.620104     125.028321      112.173068     123.384558   \n",
       "7   2022-08-15     124.227794     127.020017      112.264928     125.026399   \n",
       "8   2022-08-22     125.856563     129.043437      112.360383     126.686062   \n",
       "9   2022-08-29     127.506679     131.099094      112.457039     128.366016   \n",
       "10  2022-09-05     129.178430     133.187498      112.552986     130.065546   \n",
       "11  2022-09-12     130.872107     135.309169      112.646681     131.785794   \n",
       "12  2022-09-19     132.587991     137.464639      112.736980     133.527703   \n",
       "13  2022-09-26     134.326371     139.654445      112.822971     135.293725   \n",
       "14  2022-10-03     136.087548     141.879135      112.903576     137.085601   \n",
       "15  2022-10-10     137.871816     144.139264      112.978016     138.903891   \n",
       "16  2022-10-17     139.679474     146.435397      113.045771     140.749097   \n",
       "17  2022-10-24     141.510823     148.768098      113.253972     143.653953   \n",
       "18  2022-10-31     143.366197     151.137968      113.507594     146.501733   \n",
       "19  2022-11-07     145.245892     153.545585      113.792013     149.284406   \n",
       "20  2022-11-14     147.150236     155.991560      114.097188     152.030119   \n",
       "21  2022-11-21     149.079545     158.476499      114.415043     154.756545   \n",
       "22  2022-11-28     151.034148     161.001024      114.741283     157.477870   \n",
       "23  2022-12-05     153.014370     163.565759      115.071454     160.204483   \n",
       "24  2022-12-12     155.020555     166.171355      115.402093     162.942833   \n",
       "25  2022-12-19     157.053052     168.818458      115.730399     165.697829   \n",
       "26  2022-12-26     159.112198     171.507729      116.054758     168.473259   \n",
       "27  2023-01-02     161.198346     174.239840      116.375695     171.269717   \n",
       "28  2023-01-09     163.311846     177.015474      116.691746     174.090156   \n",
       "29  2023-01-16     165.453051     179.835323      117.001768     176.937709   \n",
       "30  2023-01-23     167.622331     182.700093      117.304860     179.814599   \n",
       "31  2023-01-30     169.820041     185.610498      117.601166     182.722756   \n",
       "32  2023-02-06     172.046582     188.567260      117.890154     185.663853   \n",
       "33  2023-02-13     174.302310     191.571129      118.171326     188.639432   \n",
       "34  2023-02-20     176.587613     194.622844      118.359831     192.762339   \n",
       "35  2023-02-27     178.902879     197.723172      118.601920     196.802065   \n",
       "36  2023-03-06     181.248501     200.872895      118.874915     200.754397   \n",
       "37  2023-03-13     183.624882     204.072792      119.170382     204.655905   \n",
       "38  2023-03-20     186.032415     207.323663      119.480655     208.540152   \n",
       "39  2023-03-27     188.471513     210.626321      119.798369     212.426651   \n",
       "40  2023-04-03     190.942591     213.981590      120.119276     216.329659   \n",
       "41  2023-04-10     193.446067     217.390308      120.440232     220.257630   \n",
       "42  2023-04-17     195.982367     220.853314      120.758388     224.217247   \n",
       "43  2023-04-24     198.551920     224.371498      121.071655     228.213915   \n",
       "44  2023-05-01     201.155152     227.945721      121.379082     232.250425   \n",
       "45  2023-05-08     203.792532     231.576887      121.679573     236.328656   \n",
       "46  2023-05-15     206.464474     235.265897      121.972411     240.452106   \n",
       "47  2023-05-22     209.171460     239.013674      122.257918     244.624476   \n",
       "48  2023-05-29     211.913944     242.821152      122.535341     248.853338   \n",
       "49  2023-06-05     214.692379     246.689283      122.804118     253.141084   \n",
       "50  2023-06-12     217.507248     250.619034      123.063817     257.489969   \n",
       "51  2023-06-19     220.359018     254.611385      123.085117     262.830918   \n",
       "52  2023-06-26     223.248184     258.667334      123.152069     268.099809   \n",
       "53  2023-07-03     226.175223     262.787895      123.250812     273.246989   \n",
       "54  2023-07-10     229.140640     266.974095      123.371251     278.314285   \n",
       "\n",
       "    tf5_labellen4  tf6_labellen8  tf7_labellen8  tf8_labellen12  \\\n",
       "0      114.586041     112.824350     112.157742      112.703790   \n",
       "1      117.300917     113.878353     112.381950      113.478875   \n",
       "2      120.080115     115.095448     112.606624      114.259289   \n",
       "3      122.925161     116.453531     112.831761      115.045071   \n",
       "4      125.837615     117.932312     113.057354      115.836257   \n",
       "5      128.819073     119.507139     113.283405      116.632883   \n",
       "6      131.871174     121.166896     113.509915      117.434989   \n",
       "7      134.995585     122.903289     113.736881      118.242610   \n",
       "8      138.194021     124.709901     113.964304      119.055786   \n",
       "9      141.468239     126.581730     114.192182      119.874554   \n",
       "10     144.820031     128.513103     114.420523      120.698953   \n",
       "11     148.251238     130.501069     114.649327      121.529021   \n",
       "12     151.763739     132.543248     114.878588      122.364798   \n",
       "13     155.359462     134.637759     115.108315      123.206323   \n",
       "14     159.040379     136.782990     115.338508      124.053635   \n",
       "15     162.808506     138.977787     115.569162      124.906774   \n",
       "16     166.665912     141.221274     115.800276      125.765781   \n",
       "17     170.614705     142.648630     116.031746      126.630695   \n",
       "18     174.657063     144.282489     116.263696      127.501557   \n",
       "19     178.795195     146.083357     116.496130      128.378408   \n",
       "20     183.031371     148.043162     116.729046      129.261289   \n",
       "21     187.367915     150.155323     116.962435      130.150242   \n",
       "22     191.807204     152.399405     117.196301      131.045309   \n",
       "23     196.351673     154.753723     117.430642      131.946531   \n",
       "24     201.003814     157.206804     117.665465      132.853951   \n",
       "25     205.766177     159.751189     117.900755      133.767612   \n",
       "26     210.641374     162.381091     118.136514      134.687556   \n",
       "27     215.632079     165.092037     118.372756      135.613826   \n",
       "28     220.741028     167.879228     118.609481      136.546467   \n",
       "29     225.971023     170.739484     118.846686      137.485522   \n",
       "30     231.324932     173.671027     119.084366      138.431034   \n",
       "31     236.805690     176.672305     119.322521      139.383049   \n",
       "32     242.416304     179.742151     119.561160      140.341612   \n",
       "33     248.159849     182.879721     119.800275      141.306766   \n",
       "34     254.039475     184.782606     120.039701      142.278558   \n",
       "35     260.058407     186.933114     120.279638      143.257034   \n",
       "36     266.219945     189.281592     120.520075      144.242238   \n",
       "37     272.527459     191.821873     120.761001      145.234218   \n",
       "38     278.984425     194.555591     121.002426      146.233020   \n",
       "39     285.594374     197.460036     121.244341      147.238691   \n",
       "40     292.360933     200.514457     121.486747      148.251278   \n",
       "41     299.287811     203.697049     121.729638      149.270828   \n",
       "42     306.378807     206.998096     121.973029      150.297391   \n",
       "43     313.637810     210.410485     122.216910      151.331013   \n",
       "44     321.068799     213.928666     122.461286      152.371743   \n",
       "45     328.675850     217.548084     122.706158      153.419631   \n",
       "46     336.463133     221.265207     122.951523      154.474726   \n",
       "47     344.434921     225.077341     123.197386      155.537076   \n",
       "48     352.595583     228.982400     123.443741      156.606733   \n",
       "49     360.949594     232.979478     123.690585      157.683745   \n",
       "50     369.501537     237.065805     123.937937      158.768165   \n",
       "51     378.256099     239.419005     124.185602      159.860042   \n",
       "52     387.218083     242.120595     124.433785      160.959428   \n",
       "53     396.392402     245.133283     124.682482      162.066375   \n",
       "54     405.784088     248.431184     124.931692      163.180935   \n",
       "\n",
       "    tf9_labellen4  tf10_labellen0  \n",
       "0      112.219870      113.670728  \n",
       "1      112.506474      115.434402  \n",
       "2      112.793806      117.225438  \n",
       "3      113.081886      119.044262  \n",
       "4      113.370701      120.891310  \n",
       "5      113.660254      122.767013  \n",
       "6      113.950556      124.671826  \n",
       "7      114.241594      126.606186  \n",
       "8      114.533378      128.570554  \n",
       "9      114.825911      130.565405  \n",
       "10     115.119190      132.591207  \n",
       "11     115.413219      134.648441  \n",
       "12     115.707999      136.737594  \n",
       "13     116.003532      138.859161  \n",
       "14     116.299823      141.013638  \n",
       "15     116.596875      143.201547  \n",
       "16     116.894681      145.423406  \n",
       "17     117.193259      147.598326  \n",
       "18     117.492600      149.805774  \n",
       "19     117.792701      152.046241  \n",
       "20     118.093573      154.320211  \n",
       "21     118.395213      156.628190  \n",
       "22     118.697627      158.970686  \n",
       "23     119.000810      161.348216  \n",
       "24     119.304763      163.761309  \n",
       "25     119.609501      166.210492  \n",
       "26     119.915002      168.696305  \n",
       "27     120.221287      171.219289  \n",
       "28     120.528358      173.780007  \n",
       "29     120.836214      176.379022  \n",
       "30     121.144856      179.016908  \n",
       "31     121.454279      181.694256  \n",
       "32     121.764492      184.411640  \n",
       "33     122.075505      187.169671  \n",
       "34     122.387381      190.232524  \n",
       "35     122.700058      193.345497  \n",
       "36     123.013526      196.509406  \n",
       "37     123.327803      199.725100  \n",
       "38     123.642868      202.993405  \n",
       "39     123.958749      206.315198  \n",
       "40     124.275436      209.691355  \n",
       "41     124.592933      213.122754  \n",
       "42     124.911241      216.610310  \n",
       "43     125.230359      220.154931  \n",
       "44     125.550288      223.757550  \n",
       "45     125.871038      227.419128  \n",
       "46     126.192607      231.140632  \n",
       "47     126.514995      234.923027  \n",
       "48     126.838206      238.767318  \n",
       "49     127.162242      242.674524  \n",
       "50     127.487107      246.645661  \n",
       "51     127.812778      250.149381  \n",
       "52     128.139285      253.702874  \n",
       "53     128.466623      257.306860  \n",
       "54     128.794793      260.962044  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comp(q[\"pred_val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0218d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 6, 20, 0, 0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[\"pred_date\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_ground",
   "language": "python",
   "name": "torch_ground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
